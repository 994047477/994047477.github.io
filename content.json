{"meta":{"title":"LiXuan's blog","subtitle":"Deeplearning|MachineLearning|ComputerVision","description":"Deeplearning|MachineLearning|ComputerVision","author":"leexuan","url":"http://yoursite.com"},"pages":[{"title":"404","date":"2018-10-24T07:55:18.000Z","updated":"2018-10-24T07:55:18.744Z","comments":true,"path":"404/index.html","permalink":"http://yoursite.com/404/index.html","excerpt":"","text":""},{"title":"about","date":"2020-01-03T07:59:35.272Z","updated":"2020-01-03T07:59:35.272Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"ResumeSelf Introduction 我是leexuan，来自安徽芜湖，21岁，复旦大学MMDB实验室硕士在读，本科毕业于合肥工业大学计算机专业，在大学期间，大二接触JAVA、程序设计竞赛、WEB开发等，大三学习python、爬虫技术、大数据技术、机器学习、深度学习，在大三暑假，获得推免资格，保研到复旦大学攻读硕士，大四开始接触计算机视觉的一些研究，大四接触的计算机视觉领域包括图像分类、目标检测、OCR、语义分割… 读研期间，我将会抽空去更新博客，将所学的一些知识(论文、书籍等)进行总结归纳。 如果你和我需要和我交流（包括竞赛、科研、编程开发、求职等）或者是博客里有些观点表述有误，可以通过邮箱联系我，请多多指教！ Contact Mail: xuanli19(AT)mail.fudan.edu.cnEducation Fudan University 2019.9 - 2022.6 M.S. in Software Engineering Research on Computer vision | Deep Learning | Machine Learning Hefei University of Technology 2015.9 - 2019.6 B.S. in Computer Science GPA:3.75/4.3 , Rank: 3/196 Skills English – CET6 Python &gt; C++ &gt; JAVA &gt; Shell Latex|MarkDown Computer Vision(Object Detection,OCR) Deep Learning(CNN|RNN|GAN) Machine Learning(LR|SVM|GBDT|NB|KNN|K-Means|PCA) NLP (Word Embedding– word2vec ,TextCNN etc.. ) Hadoop,Hive (simple big data processing ) Web Spider Simple website building (use JSP and Servlet) Linux|MacOS Data Mining Pytorch &gt; Tensorflow Honors &amp; Awards 全国高中数学联赛三等奖 全国大学生数学竞赛安徽赛区三等奖 安徽省程序设计竞赛二等奖 安徽省大数据技术与应用竞赛冠军 安徽省三创赛二等奖 合肥工业大学一等奖学金和三好学生等 合肥工业大学优秀毕业生,安徽省优秀毕业生 My Course Presentation AugBoost(enhanced GBDT) OCR MapReduce My Projects hotel-management-system(DataBase Project) … Links czy，hit在读硕士,NLP ycc, seu在读硕士,NLP sixzeroo, 本科室友,字节跳动工作"},{"title":"categories","date":"2019-01-04T08:32:33.441Z","updated":"2019-01-04T08:32:33.441Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"","date":"2019-12-08T03:33:34.300Z","updated":"2019-12-08T03:33:34.300Z","comments":true,"path":"downloads/index.html","permalink":"http://yoursite.com/downloads/index.html","excerpt":"","text":"My Slides Slides Download! AugBoost MapReduce"},{"title":"search","date":"2018-10-24T07:55:10.000Z","updated":"2018-10-24T07:55:10.868Z","comments":true,"path":"search/index.html","permalink":"http://yoursite.com/search/index.html","excerpt":"","text":""},{"title":"tags","date":"2019-01-04T08:25:56.849Z","updated":"2019-01-04T08:25:56.849Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Linux 定时任务","slug":"Linux-定时任务","date":"2019-12-18T04:07:42.000Z","updated":"2019-12-18T04:07:42.969Z","comments":true,"path":"2019/12/18/Linux-定时任务/","link":"","permalink":"http://yoursite.com/2019/12/18/Linux-定时任务/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"Tmux 简单使用","slug":"Tmux-简单使用","date":"2019-12-18T04:07:03.000Z","updated":"2019-12-18T04:07:03.764Z","comments":true,"path":"2019/12/18/Tmux-简单使用/","link":"","permalink":"http://yoursite.com/2019/12/18/Tmux-简单使用/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"docker 深度学习环境部署","slug":"docker-深度学习环境部署","date":"2019-12-18T04:06:41.000Z","updated":"2019-12-18T04:06:41.745Z","comments":true,"path":"2019/12/18/docker-深度学习环境部署/","link":"","permalink":"http://yoursite.com/2019/12/18/docker-深度学习环境部署/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"OOV problem solution","slug":"OOV-problem-solution","date":"2019-12-18T04:01:10.000Z","updated":"2019-12-18T04:02:13.353Z","comments":true,"path":"2019/12/18/OOV-problem-solution/","link":"","permalink":"http://yoursite.com/2019/12/18/OOV-problem-solution/","excerpt":"","text":"","categories":[],"tags":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://yoursite.com/tags/Deep-Learning/"},{"name":"Language Model","slug":"Language-Model","permalink":"http://yoursite.com/tags/Language-Model/"}]},{"title":"AugBoost","slug":"AugBoost","date":"2019-10-23T10:20:04.000Z","updated":"2019-10-23T10:20:34.836Z","comments":true,"path":"2019/10/23/AugBoost/","link":"","permalink":"http://yoursite.com/2019/10/23/AugBoost/","excerpt":"","text":"","categories":[],"tags":[{"name":"GBDT","slug":"GBDT","permalink":"http://yoursite.com/tags/GBDT/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://yoursite.com/tags/Machine-Learning/"}]},{"title":"线性回归正则化","slug":"线性回归正则化","date":"2019-10-23T10:18:44.000Z","updated":"2019-10-23T10:19:08.159Z","comments":true,"path":"2019/10/23/线性回归正则化/","link":"","permalink":"http://yoursite.com/2019/10/23/线性回归正则化/","excerpt":"","text":"","categories":[],"tags":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://yoursite.com/tags/Machine-Learning/"}]},{"title":"朴素贝叶斯","slug":"NaiveBayes","date":"2019-10-23T10:17:31.000Z","updated":"2019-10-23T10:18:17.824Z","comments":true,"path":"2019/10/23/NaiveBayes/","link":"","permalink":"http://yoursite.com/2019/10/23/NaiveBayes/","excerpt":"","text":"","categories":[],"tags":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://yoursite.com/tags/Machine-Learning/"}]},{"title":"PCA","slug":"PCA","date":"2019-10-22T03:19:59.000Z","updated":"2019-10-22T03:23:41.974Z","comments":true,"path":"2019/10/22/PCA/","link":"","permalink":"http://yoursite.com/2019/10/22/PCA/","excerpt":"","text":"PCA（Principal Component Analysis） 流程 原理 正交化分解 Reference[1] https://zhuanlan.zhihu.com/p/21580949","categories":[],"tags":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://yoursite.com/tags/Machine-Learning/"}]},{"title":"机器学习评测指标","slug":"metrics","date":"2019-10-08T06:27:18.000Z","updated":"2019-10-08T08:20:51.816Z","comments":true,"path":"2019/10/08/metrics/","link":"","permalink":"http://yoursite.com/2019/10/08/metrics/","excerpt":"","text":"机器学习评测指标与工具 ROC曲线 AUC值 PR曲线 MAP值 混淆矩阵 Q&amp;AQ: 为什么ROC曲线不受样本不均衡问题的影响? A: 参考 https://blog.csdn.net/songyunli1111/article/details/82285266","categories":[],"tags":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://yoursite.com/tags/Machine-Learning/"}]},{"title":"pix2pix论文阅读","slug":"pix2pix","date":"2019-09-22T03:21:40.000Z","updated":"2019-09-22T07:18:53.096Z","comments":true,"path":"2019/09/22/pix2pix/","link":"","permalink":"http://yoursite.com/2019/09/22/pix2pix/","excerpt":"论文:《Image-to-Image Translation with Conditional Adversarial Networks》 概述pix2pix网络基于conditional gan改进，CGAN的生成器网络是输入噪声和条件y，而pix2pix生成器网络是只有一个输入Image，然后经过生成网络(类似U-net等网络)，生成一张image.","text":"论文:《Image-to-Image Translation with Conditional Adversarial Networks》 概述pix2pix网络基于conditional gan改进，CGAN的生成器网络是输入噪声和条件y，而pix2pix生成器网络是只有一个输入Image，然后经过生成网络(类似U-net等网络)，生成一张image.举个栗子，正因为网络结构的差异，这些网络可以完成不同的任务，比如普通的GAN，只给一堆二次元人物头像，然后让gan学习到从输入噪声生成出和原二次元头像训练图片风格很相似但是内容不一样的图片.对于CGAN，可以给输入条件label和对应的真实数据进行训练，比如使用Mnist数据集，将one-hot标签[0,1,0,0…]和数字1的图像一起送给生成器训练，其他的对应送给CGAN训练。不断迭代学习，最后能够给一个噪声和标签[0,0,1,0,0…]就能生成一个数字2的图像。pix2pix网络，主要是对图像做翻译，给定一对图片[a1,a2,a3…][b1,b2,b3…]送入pix2pix网络学习，生成器输入a1，生成出一个image，然后使用鉴别器和对应标签b1一起打分，经过不断地训练,最后就能完成图像翻译的工作，如下图效果所示。 参考[1] https://blog.csdn.net/weixin_38148834/article/details/95998627","categories":[],"tags":[{"name":"Image Translation","slug":"Image-Translation","permalink":"http://yoursite.com/tags/Image-Translation/"}]},{"title":"GBDT 与 XGBoost","slug":"xgboost","date":"2019-08-26T03:21:40.000Z","updated":"2019-08-26T03:22:25.152Z","comments":true,"path":"2019/08/26/xgboost/","link":"","permalink":"http://yoursite.com/2019/08/26/xgboost/","excerpt":"","text":"TODO","categories":[],"tags":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://yoursite.com/tags/Machine-Learning/"}]},{"title":"Single Shot Detector","slug":"ssd","date":"2019-08-26T03:21:27.000Z","updated":"2019-08-26T03:22:55.948Z","comments":true,"path":"2019/08/26/ssd/","link":"","permalink":"http://yoursite.com/2019/08/26/ssd/","excerpt":"","text":"TODO","categories":[],"tags":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://yoursite.com/tags/Deep-Learning/"},{"name":"Object Detection","slug":"Object-Detection","permalink":"http://yoursite.com/tags/Object-Detection/"}]},{"title":"DenseNet","slug":"DenseNet","date":"2019-08-23T09:17:45.000Z","updated":"2019-08-23T09:28:25.199Z","comments":true,"path":"2019/08/23/DenseNet/","link":"","permalink":"http://yoursite.com/2019/08/23/DenseNet/","excerpt":"","text":"DenseNet 优点: 特征利用率高 参数稍微减少点 特征表达更加robust 缺点: 耗费显存(concat拼接操作)","categories":[],"tags":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://yoursite.com/tags/Deep-Learning/"}]},{"title":"R-FCN 更快的检测","slug":"R-FCN","date":"2019-08-20T07:30:34.000Z","updated":"2019-09-06T00:21:17.595Z","comments":true,"path":"2019/08/20/R-FCN/","link":"","permalink":"http://yoursite.com/2019/08/20/R-FCN/","excerpt":"R-FCN: Object Detection via Region-based Fully Convolutional Networks","text":"R-FCN: Object Detection via Region-based Fully Convolutional Networks 概述R-FCN 提出了position-sensitive score maps去解决平移不变性，而且可以轻易为R-FCN替换各种全卷积特征抽取网络(如ResNet等)，相比较Faster R-CNN系列，能够共享更多的运算，提升速度。","categories":[],"tags":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://yoursite.com/tags/Deep-Learning/"},{"name":"Object Detection","slug":"Object-Detection","permalink":"http://yoursite.com/tags/Object-Detection/"}]},{"title":"object detection tutorial","slug":"object-detection-tutorial","date":"2019-08-17T12:51:46.000Z","updated":"2019-08-20T08:55:53.465Z","comments":true,"path":"2019/08/17/object-detection-tutorial/","link":"","permalink":"http://yoursite.com/2019/08/17/object-detection-tutorial/","excerpt":"OverFeat 提出将图像分类，目标检测分割等任务使用同一套网络做特征提取的思想，前面的几层网络特征抽取层可以公用，只需要改动最后面几层输出层即可，为后来很多的目标检测算法提供了改进思路","text":"OverFeat 提出将图像分类，目标检测分割等任务使用同一套网络做特征提取的思想，前面的几层网络特征抽取层可以公用，只需要改动最后面几层输出层即可，为后来很多的目标检测算法提供了改进思路 SSD FPNR-FCNRetinaNet 主要贡献在于提出 Focal Loss，解决了类别不均衡问题(主要包括平衡easy sample 和 hard sample，以及True sample 和 False sample的权重)提高精度，解决了One-stage detector 精度不如 Two-stage detector的问题. SPPNet 首次提出使用roi pooling层，使得不同size的feature池化成统一scale，这样就不用再输入图片时进行resize处理了","categories":[],"tags":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://yoursite.com/tags/Deep-Learning/"},{"name":"Object Detection","slug":"Object-Detection","permalink":"http://yoursite.com/tags/Object-Detection/"}]},{"title":"YOLOv2/v3的改进","slug":"yolo","date":"2019-08-17T12:19:02.000Z","updated":"2019-08-17T13:01:52.743Z","comments":true,"path":"2019/08/17/yolo/","link":"","permalink":"http://yoursite.com/2019/08/17/yolo/","excerpt":"YOLOv1缺点 对小目标检测效果不好 提取的region太少了，7*7*2 坐标定位不准确","text":"YOLOv1缺点 对小目标检测效果不好 提取的region太少了，7*7*2 坐标定位不准确 YOLOv2 - Better,Faster,StrongerBetter Batch Normalization 引入 Anchor Box 来预测Bouding box 维度聚类，使用K-means聚类bounding box，可以找到更好地box宽高 Faster 借鉴VGG,NIN思想，多次使用1*1和3*3等较小的卷积核以及使用全局平均池化，设计出darknet-19模型，大大节约计算量 Stronger COCO数据集少，ImageNet数据集多，使用wordtree结合了两个数据集的标签，使得能够检测9000多种目标 YOLOv3改进 特征提取器，设计Darknet-53，融合了darknet-19和残差网络等，更高效地提取特征 使用了多尺度预测，类似于 FPN(Feature Pyramid Network-特征金字塔网络)，三层不同scale的特征一起做bbox regression 分类预测使用二元交叉熵损失，边界框bbox regression 使用 平方和距离误差损失","categories":[],"tags":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://yoursite.com/tags/Deep-Learning/"}]},{"title":"Fine tuning Tutorial","slug":"Transfer-Learning","date":"2019-08-15T02:14:10.000Z","updated":"2019-08-15T02:47:58.205Z","comments":true,"path":"2019/08/15/Transfer-Learning/","link":"","permalink":"http://yoursite.com/2019/08/15/Transfer-Learning/","excerpt":"介绍 在深度学习领域，进行一个模型的训练往往需要大量的数据，否则会造成无法很好地拟合的问题。但是大多数情况下，现有数据量都是不够让模型很好地训练。","text":"介绍 在深度学习领域，进行一个模型的训练往往需要大量的数据，否则会造成无法很好地拟合的问题。但是大多数情况下，现有数据量都是不够让模型很好地训练。 举个栗子 直接 from scratch 训练容易过拟合，比如你有少量训练图像都是雪地里的阿拉斯加犬，然后直接from scratch去训练模型，经过很多epoch的迭代训练，很可能会造成模型学到的特征阿拉斯加犬都是在雪地里面，然后你给一张在草地里的阿拉斯加犬就无法识别，反而你给一个在雪地里面的藏獒被错误识别成阿拉斯加犬。这就是过拟合，学习到了图片中非常个性的特征，不具有很好的泛化能力。 方法Fine tuning就能较好地解决这个问题，现在常用的解决方案有两种: 使用pretrained model 做Feature extract，然后再去做分类等任务。(也就是固定预训练模型参数，把预训练模型当成一个完整的特征提取器，然后将给定image转化成一个feature vector) 使用pretrained model 做微调，增删模型后面若干层的网络结构，然后可以选择保留预训练模型的参数，这样可以保持模型的泛化能力，同时和后面调整的网络一起联合训练，使得模型更好地学习到新的数据特征。 优点 解决了我们小样本下使用复杂网络上容易过拟合的问题 节省了训练时间，因为网络前面几层提取的特征具备一定的泛化能力 技巧在数据量非常少的时候，建议使用预训练模型做特征抽取。在数据量较大的时候，建议使用fine tuning微调。 实战TODO","categories":[],"tags":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://yoursite.com/tags/Deep-Learning/"}]},{"title":"R-CNN系列目标检测网络解析","slug":"RCNN系列目标检测网络解析","date":"2019-08-13T12:44:43.000Z","updated":"2019-08-17T12:18:27.183Z","comments":true,"path":"2019/08/13/RCNN系列目标检测网络解析/","link":"","permalink":"http://yoursite.com/2019/08/13/RCNN系列目标检测网络解析/","excerpt":"r-cnn:https://arxiv.org/pdf/1311.2524.pdffast r-cnn: https://arxiv.org/pdf/1504.08083.pdffaster r-cnn : https://arxiv.org/pdf/1506.01497.pdf 起源目标检测问题的起源:最初受到传统计算机视觉方法启发，使用滑动窗口检测器+SVM等分类器。但是有个问题:窗口的大小难以确定，因为物体是大小多样的。使用深度学习做目标检测的比较早期的方法就是R-CNN。","text":"r-cnn:https://arxiv.org/pdf/1311.2524.pdffast r-cnn: https://arxiv.org/pdf/1504.08083.pdffaster r-cnn : https://arxiv.org/pdf/1506.01497.pdf 起源目标检测问题的起源:最初受到传统计算机视觉方法启发，使用滑动窗口检测器+SVM等分类器。但是有个问题:窗口的大小难以确定，因为物体是大小多样的。使用深度学习做目标检测的比较早期的方法就是R-CNN。 R-CNN(Region convolutional neural network)流程输入一张图片，使用selective search（根据图像特征） 方法来提取region proposal （区域建议窗口），大约2000个左右，然后将 提取出来的2000个窗口 resize到统一尺寸，来符合CNN的输入，分别丢入CNN网络，然后用设计好的CNN的网络来提取特征，然后在最后加上SVM分类和BBox回归。 缺点需要对2000个proposal region逐个做CNN提取、分类、预测，很慢，而且有大量重复计算. 可以考虑的改进方案： 从窗口角度： 合理地选择窗口，减少运算量，提高运算效率 从网络结构的角度： 比如使用VGG16 ，resnet inception 等网络，来提高特征提取的精度和速度 Fast R-CNN流程先做SS，选出2000个窗口，但是不切出来，然后对原图整个做CNN提取特征，然后在CNN输出的特征图中按照2000个窗口的位置来切割，与之前先提取窗口，然后对每个窗口做CNN特征提取的效果是一样的。但是Fast-Rcnn只需要对大图做一次CNN，而RCNN需要对2000个小图分别做CNN，运算量比较大。另一个是用softmax来替换SVM，然后最后训练是使得multi-loss下降，multi-loss 包括bbox回归损失和分类损失。 改进(相对于R-CNN) 先使用卷积网络对图像进行特征提取，然后共享这个提取出来的feature map 因为使用SS提取的区域大小是不固定的，所以经过特征抽取网络后提取出来的feature map大小是不相同的，所以在特征抽取到分类回归层中间加上了ROI pooling网络结构，用于将不同大小的feature map分解成统一尺寸的特征(ROI pooling 的思想借鉴于 SPP-Net)。 使用softmax替换了SVM多分类器 缺点 使用SS的方法来提取2000个region开销太大，成为优化瓶颈，能否使用神经网络来寻找目标 Faster R-CNN 流程提出RPN网络（region proposal network）用于提取region，先在每个点找9个如图所示的anchor box 完整流程图 优点 使用RPN网络代替传统SS(Selective Search)提取region proposal的策略，大量缩短时间 Mask R-CNN改进 使用ROI Align 代替 ROI Pooling，使得检测更加精确 使用更强的特征提取网络ResNeXt替换VGG 在分类和回归分支加一个pixel级别的K(K是类别数)个feature map，用于预测原来图片每个pixel属于哪些类别","categories":[],"tags":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://yoursite.com/tags/Deep-Learning/"},{"name":"Object Detection","slug":"Object-Detection","permalink":"http://yoursite.com/tags/Object-Detection/"}]},{"title":"“好而不同”的集成学习","slug":"解析集成学习","date":"2019-08-11T05:58:31.000Z","updated":"2019-08-13T12:44:12.778Z","comments":true,"path":"2019/08/11/解析集成学习/","link":"","permalink":"http://yoursite.com/2019/08/11/解析集成学习/","excerpt":"集成学习（Ensemble Learning）概述集成学习的思想就是组合多个弱学习器，得到一个强学习器。但注意，弱学习器不能太弱，比如在分类中，弱学习器的准确率最少要达到50%.","text":"集成学习（Ensemble Learning）概述集成学习的思想就是组合多个弱学习器，得到一个强学习器。但注意，弱学习器不能太弱，比如在分类中，弱学习器的准确率最少要达到50%. “好而不同”集成学习强调”好而不同”，这里的”好”是指学习器效果还不错，只要不太差就行；这里的”不同”指的是这些要集成的学习器各自在不同的方面还不错，集合在一起就能互相弥补，正所谓“三个臭皮匠赛过诸葛亮”. 针对每个学习器的个体，在选择弱学习器的时候，倾向于选择神经网络(Neural Network)，决策树(Decision Tree)这种类型(给定数据训练出来的学习器有一定随机性)，而不是选择SVM,朴素贝叶斯这种(对给定数据训练出来的学习器相差不大的学习器)。举个栗子，因为如果选择SVM可能学出的多个学习器是相似的，集成在一起就取不到更好的效果。但是如果选择决策树，训练出来的多个学习器很可能分支决策很不相同。所以多个”各有所长”的弱学习器就有机会集成为一个强学习器。另一方面，集成学习主要分为两种策略，Bagging和Boosting，在Bagging中首先是进行对给定数据进行N次Bootstrap抽样（又放回的抽样），然后训练N个弱学习器，这也体现了”不同”.在Boosting中，得到的多个学习器是在不同权重的数据样本下训练得到的，所以也是各有”不同”。","categories":[],"tags":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://yoursite.com/tags/Machine-Learning/"},{"name":"Ensemble Learning","slug":"Ensemble-Learning","permalink":"http://yoursite.com/tags/Ensemble-Learning/"}]},{"title":"深入理解ResNet","slug":"深入理解ResNet","date":"2019-08-09T10:55:56.000Z","updated":"2019-08-14T01:47:47.173Z","comments":true,"path":"2019/08/09/深入理解ResNet/","link":"","permalink":"http://yoursite.com/2019/08/09/深入理解ResNet/","excerpt":"ResNet能够work的主要原因: 作者说残差结构是为了解决网络退化的问题，作者猜测","text":"ResNet能够work的主要原因: 作者说残差结构是为了解决网络退化的问题，作者猜测 We conjecture that the deep plain nets may have exponentially low convergence rates, which impact the reducing of the training error. The reason for such optimization difficulties will be studied in the future. 认为 deep plain nets 可能有指数级低收敛率，限制了训练误差的进一步降低。他简单地比较了残差结构和常规结构在求解本征映射(identity map)时的优化难度，显然求解 F(x)=0 比求解 H(x) = x 容易得多也就是说能够更好地学习到差分特征，相当更容易学习到残差的那一部分。(这是ResNet有效地最主要原因) 残差网络对数据波动更敏感 我们回到设计 ResNet 的初衷： 为了解决深度网络的 退化 问题 。该问题的直接表现形式为： 深度网络在的训练误差比浅层网络高，无法做到使深层网络在训练数据集上“ 过拟合 ”。那么如何做到“过拟合”呢？ 答案就是我们需要使网络对数据波动更敏感，尽可能地去准确描述数据。而残差网络就是这样的一种网络结构。假设某几层 layer 要学习的函数 H(x) 如紫线所示，红色点表示采样点，对应一个数据样本。 在ResNet 中激活函数全部采用 ReLU， 我们知道 采用 ReLU 的网络是局部空间的线性网络的组合。对于数据点（5,5.1），即我们的 input 为5， 期望输出为5.1，假设为 plain network， 我们在 x =5 的附近，学习到的线性参数值为 w = 5.1/5 , 若数据点变成（5,5.2），我们仍可以用 w= 5.1/5 的线性网络近似，因为此时网络输出 5.1 与理想值 5.2 只相差 2% 而已. 所以在 plain net 中，网络对 数据不敏感。 数据的波动指的是相对对角线 y= x 的波动, 残差网络的思想是：我们用 y= x 先去粗略拟合数据， “波动”也即“拟合残差”就交给 weight layer 去拟合。数据点（5,5.1）对应的残差为（5,0.1），此时假设学习到的参数为 w=0.1/5 。同样地，若数据点变成（5,5.2），对应的残差为（5,0.2）。显然地，我们不可以用 0.1/5 近似了，因为若用0.1/5 近似，网络输出 0.1 和 0.2 相差了100%。网络需要调整 w 的值，以尽可能精确地描述残差。所以综上所述，残差网络对数据变得敏感，也即对“数据波动更敏感”，更容易做到“过拟合”。 集成学习思想，ResNet是由很多条路径集成学习得到的，对于每个block如果残差为0就退化为直连。如果所有resblock的残差都是0，那么就退化成VGG网络。 特征表示，跳层连接使得表达特征更加丰富，比如说前面网络层的浅层特征能够和深层的特征融合。2017年的DenseNet网络有类似的设计。 缓解梯度消失问题，梯度能够直接传到skip connection前面的网络层（不是主要原因，作者说这个梯度消失的问题使用Batch Normalization就能解决，但resNet确实有缓解梯度消失的效果） 参考https://zhuanlan.zhihu.com/p/54289848https://www.jianshu.com/p/ca6bee9eb888","categories":[],"tags":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://yoursite.com/tags/Deep-Learning/"},{"name":"ResNet","slug":"ResNet","permalink":"http://yoursite.com/tags/ResNet/"},{"name":"CNN","slug":"CNN","permalink":"http://yoursite.com/tags/CNN/"}]},{"title":"Batch Normalization解析","slug":"Batch-Normalization","date":"2019-08-08T08:47:43.000Z","updated":"2019-08-17T06:44:14.845Z","comments":true,"path":"2019/08/08/Batch-Normalization/","link":"","permalink":"http://yoursite.com/2019/08/08/Batch-Normalization/","excerpt":"论文链接 : https://arxiv.org/abs/1502.03167","text":"论文链接 : https://arxiv.org/abs/1502.03167 介绍Batch Normalization 是批归一化，用来解决神经网络中协方差偏移问题，就是每一层的分布很混乱，除非从第一层开始每一层的输入的分布都很有效，否则就得不到好的效果。如下图所示。 所以，为了解决这个问题，我们引入了Batch Normalization. 介绍一下在机器学习中，是如何做feature scaling，因为输入的不同变量分布不同，比如说x1可能是代表房子的房间数量，x2代表房子的大小多少平方，那么x2和x1很显然不属于统一量纲，所以要做归一化，如下图所示。 原理顾名思义，Batch Normalization是对一个batch的数据做处理， 求均值 除以标准差 仿射变换（可选）（有时候需要把均值和方差调整到某些范围时可以加上） 然后将Batch Normalization的结果送给激活函数层，才能比较好的发挥激活函数的作用。 举个栗子，比如像Sigmoid函数，如果不做Batch Normalization，可能会导致输入分布在两边（就是不集中在[-1，1] ），梯度就很小，链式相乘之后就会接近于0，做了Batch Normalization，把输入集中在0附近，使得激活函数更好地发挥作用。 pytorch实现pytorch api1234567891011torch.nn.BatchNorm1d(num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)torch.nn.BatchNorm2d(num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) affine是仿射，track_running_stats是保留在训练时候的数据方差和均值，从而运用到测试中，因为在测试中是不方便计算方差和均值的，当batch_size很小的时候，应该设置为False。 训练模式下 track_running_stats=True, 这是常用的training时期待的行为，running_mean 和running_var会跟踪不同batch数据的mean和variance，但是仍然是用每个batch的mean和variance做normalization。 训练模式下, track_running_stats=False, 这时候running_mean 和running_var不跟踪跨batch数据的statistics了，但仍然用每个batch的mean和variance做normalization。 测试模式下, track_running_stats=True, 这是我们期待的test时候的行为，即使用training阶段估计的running_mean 和running_var。 测试模式下, track_running_stats=False，仍然用每个batch的mean和variance做normalization。 要注意在训练的时候选择model.train()模式在测试的时候选择model.eval()模式，这样Batch Normalization中的参数才会固定。 知乎上有个BN为什么能够解决梯度消失和爆炸问题的回答写的很好:https://www.zhihu.com/question/38102762/answer/391649040 参考:https://www.zhihu.com/question/282672547","categories":[],"tags":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://yoursite.com/tags/Deep-Learning/"}]},{"title":"经典CNN结构解析与实现","slug":"CNN-Network","date":"2019-08-02T01:36:03.000Z","updated":"2019-08-18T08:59:12.005Z","comments":true,"path":"2019/08/02/CNN-Network/","link":"","permalink":"http://yoursite.com/2019/08/02/CNN-Network/","excerpt":"实现代码地址：Github","text":"实现代码地址：Github 目录 AlexNet VGG Google Inception Net ResNet DenseNet MobileNet Shuffle Net AlexNet 首次使用CNN组建的深度网络在ImageNet上达到最好效果 它使用Relu 激活函数代替了传统的激活函数(Sigmoid/Tanh) 使用Dropout 解决过拟合问题 计算量较大 VGG VGG使用连续的几个3*3卷积核代替AlexNet中较大的卷积核，减少计算量。 VGG Net中采用的卷积核是非常一致的，全都是3*3的filter VGG 分为4-5个block，每个block包含若干个3*3的卷积层和一个2*2的MaxPooling层所以得到的conv4_3是16倍的下采样的feature map Inception Net 设计了Inception Block，采用了不同尺度的filter，size为1*1,3*3,5*5，获得了不同scale的特征，具有对不同尺度特征的提取能力，而且还通过1*1的卷积层来大大降低运算。 在卷积层结束后，使用全局AveragePooling，避免使用全连接层 ResNet 在VGG网络后，研究人员发现仅仅堆叠越来越多层的CNN 或 全连接层等是无法再提高准确率，主要原因就是梯度消失的问题，因为在多层神经网络中，梯度传到最前面的网络层就非常接近0了，导致前面网络层的参数更新很慢。于是提出ResNet去解决这个梯度消失的问题。 ResNet主要是设计了一个ResBlock。ResBlock使用skip connect 跳层连接，使得梯度能够有效地回传，从而参数得以更新，才敢设计比VGG深很多的网络。 DenseNet 设计思路与ResNet非常相似，但实际上一个很大的区别是，它是做多channel的特征的拼接，而ResNet是做求和计算 DenseNet主要包含两个模块，DenseBlock和Transition层，每个DenseBlock的内部是将第N层之前的feature map都经过卷积处理到固定shape拼接到第N层，Transition作为缓冲层是将维度进行降低，减少计算量 优点：梯度消失问题得到改善，特征复用，使用了multi-scale的特征,参数少，因为特征图的channel不像之前的那么多 MobileNet 解决深度学习网络移动设备上的运行速度问题，提出的高效的网络，在模型大小显著减少的情况下，对准确率不造成太大影响 使用 depthwise separable convolution 代替传统卷积网络。 depthwise separable convolution depthwise卷积 对输入的D*D*M的M个通道，每个通道使用一个filter进行卷积，即使用M个卷积核分别对M个通道进行卷积，得到feature mapD*D*M pointwise卷积 对经过上面步骤得到的feature mapD*D*M的每个cell(shape为 1*1*M) 使用1*1*M*N卷积核进行卷积 SqueezeNetShuffle NetNIN(Network In Network) 提出1*1的卷积filter来构建新的卷积单元 1*1的卷积核的优势: 减少运算，加强多通道的特征融合，提高模型非线性变换能力 使用average pooling 来代替最后面的全连接层，大大减少计算量","categories":[],"tags":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://yoursite.com/tags/Deep-Learning/"},{"name":"Image Classification","slug":"Image-Classification","permalink":"http://yoursite.com/tags/Image-Classification/"},{"name":"Feature Extract","slug":"Feature-Extract","permalink":"http://yoursite.com/tags/Feature-Extract/"}]},{"title":"《You Only Look Once》YOLOv1论文笔记","slug":"YOLOv1","date":"2019-08-01T08:25:01.000Z","updated":"2019-08-02T01:18:14.441Z","comments":true,"path":"2019/08/01/YOLOv1/","link":"","permalink":"http://yoursite.com/2019/08/01/YOLOv1/","excerpt":"YOLO v1论文:《You Only Look Once: Uniﬁed, Real-Time Object Detection》论文地址：http://www.arxiv.org/pdf/1506.02640.pdf","text":"YOLO v1论文:《You Only Look Once: Uniﬁed, Real-Time Object Detection》论文地址：http://www.arxiv.org/pdf/1506.02640.pdf 简介作者提出把目标检测任务当做回归任务来做，用一个神经网络来完成bbox(bounding box)以及class probabilities(类别概率)的回归，因为网络是单个完整的，不同于Faster R-CNN是分为RPN(Region Proposal Network,区域建议网络，用来生成一些proposal，输给后续的回归网络)和回归网络。所以YOLO网络是可以端到端的训练。 网络结构 YOLO系统流程 输入图片img resize到指定尺寸 通过预先设计好的多层CNN(一般包括特征抽取的VGG，以及回归层等) 根据回归层输出的坐标和置信度confidence来对proposal进行筛选 主要的网络结构如图如上图所示，输入一个图片，resize到448*448的，经过N多卷积网络层得到7*7*30的feature map 图片源于知乎用户这个维度30的意义如下图所示，包括confidence*2,(x1,y1)(x2,y2)四个坐标*2,20个类别概率(哪个概率大就是哪一类，用softmax实现)，每一个30维的vector代表一个7*7的feature map 的每一个cell里面的信息。 置信度在训练时计算如上图所示，Pr(object)就是选择一个cell中与训练样本ground truth的IOU大的那个proposal为1，另一个为0，所以这个置信度即为IOU或0。 Loss Function 如图所示，损失函数包括三部分：坐标回归损失、分类损失和置信度损失。坐标回归损失只是针对那些被认定为包含object的proposal才进行计算，对于没有检测到object的proposal不需要坐标回归的loss，分类损失也是检测到object的proposal要计算。还有一个置信度误差，不管有没有检测到object都要去计算。 Problem 每个vector的30维中只有一个20维的class probability ，但是有两个5维(4个坐标+1个置信度)向量，这代表了实际上7*7的feature map中的每一个单元都只能预测一个object，那么对于每个object为什么要使用两个回归向量呢？是为了精确地解决回归问题，最后这两个回归出来的proposal最多保留IOU大的那一个。","categories":[],"tags":[{"name":"Object Detection","slug":"Object-Detection","permalink":"http://yoursite.com/tags/Object-Detection/"},{"name":"Computer Vision","slug":"Computer-Vision","permalink":"http://yoursite.com/tags/Computer-Vision/"},{"name":"Notes","slug":"Notes","permalink":"http://yoursite.com/tags/Notes/"}]},{"title":"机器学习西瓜书第一章","slug":"ML_1","date":"2019-07-16T11:51:36.000Z","updated":"2019-09-22T01:33:21.498Z","comments":true,"path":"2019/07/16/ML_1/","link":"","permalink":"http://yoursite.com/2019/07/16/ML_1/","excerpt":"第一章 绪论归纳偏好 （挑选假设函数的基准） 一般根据“奥卡姆剃刀”原则，也就是选择最简单的假设函数。 如无必要，勿增实体。 比如说给定有限训练集，有很多假设都能使得结果与有限训练集标签相似，这时候需要一个准则来在这个庞大的假设空间中选择假设进行启发，就是奥卡姆剃刀准则。","text":"第一章 绪论归纳偏好 （挑选假设函数的基准） 一般根据“奥卡姆剃刀”原则，也就是选择最简单的假设函数。 如无必要，勿增实体。 比如说给定有限训练集，有很多假设都能使得结果与有限训练集标签相似，这时候需要一个准则来在这个庞大的假设空间中选择假设进行启发，就是奥卡姆剃刀准则。 没有归纳偏执或者归纳偏执太宽泛会导致 Overfitting，限制过大的归纳偏执也是有问题的，如果数据本身并不是线性的，强行用线性函数去做回归通常并不能得到好结果。 “”没有免费的午餐“ No Free Lunch Theorem定理: 总误差与学习算法无关，它们的期望性能相同。（NFL前提：所有“问题”出现的机会相同，或所有问题同等重要，但实际情形并不是这样） NFL定理最重要的寓意：脱离具体问题，空泛的谈论“什么学习算法更好”毫无意义。因为若考虑所有潜在的问题，则所有学习算法都一样好，要谈论算法的相对优劣，必须要针对具体的学习问题，在某些问题上表现好的学习算法，在另一些问题上却可能不尽如人意。学习算法自身的归纳偏好与问题是否相配，往往会起到决定性的作用。 参考: https://www.jianshu.com/p/b26b85fac9ad","categories":[],"tags":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://yoursite.com/tags/Machine-Learning/"},{"name":"西瓜书","slug":"西瓜书","permalink":"http://yoursite.com/tags/西瓜书/"}]},{"title":"Hello World","slug":"hello-world","date":"2017-05-26T03:21:36.000Z","updated":"2019-08-15T02:50:57.297Z","comments":true,"path":"2017/05/26/hello-world/","link":"","permalink":"http://yoursite.com/2017/05/26/hello-world/","excerpt":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}