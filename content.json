{"meta":{"title":"LiXuan's blog","subtitle":"Deeplearning|MachineLearning|ComputerVision","description":"Deeplearning|MachineLearning|ComputerVision","author":"leexuan","url":"http://yoursite.com"},"pages":[{"title":"404","date":"2018-10-24T07:55:18.000Z","updated":"2018-10-24T07:55:18.744Z","comments":true,"path":"404/index.html","permalink":"http://yoursite.com/404/index.html","excerpt":"","text":""},{"title":"search","date":"2018-10-24T07:55:10.000Z","updated":"2018-10-24T07:55:10.868Z","comments":true,"path":"search/index.html","permalink":"http://yoursite.com/search/index.html","excerpt":"","text":""},{"title":"tags","date":"2019-01-04T08:25:56.849Z","updated":"2019-01-04T08:25:56.849Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""},{"title":"about","date":"2019-08-11T06:00:25.814Z","updated":"2019-08-11T06:00:25.808Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"ResumeSelf Introduction 我是leexuan，来自安徽芜湖，21岁，本科毕业于合肥工业大学计算机专业，在大学期间，大二接触JAVA、程序设计竞赛、WEB开发等，大三学习python、爬虫技术、大数据技术、机器学习、深度学习，在大三暑假，获得推免资格，保研到复旦大学攻读硕士，大四开始接触计算机视觉的一些研究，大四接触的计算机视觉领域包括图像分类、目标检测、OCR、语义分割… 读研期间，我将会抽空去更新博客，将所学的一些知识(论文、书籍等)进行总结归纳。 如果你和我需要和我交流（包括竞赛、科研、编程开发、求职等）或者是博客里有些观点写的有误，可以通过邮箱联系我，请多多指教！ Contact Mail: 19212010022(AT)mail.fudan.edu.cnEducation Fudan University 2019.9 - 2022.6 M.S. in Software Engineering Research on computer vision and Deep Learning Hefei University of Technology 2015.9 - 2019.6 B.S. in Computer Science GPA:3.75/4.3 , Rank: 3/196 Skills English – CET4,CET6 Python Computer Vision(Object Detection) Deep Learning Machine Learning Hadoop,Hive (simple big data processing ) Web Spider Simple website building (use JSP and Servlet) Linux/MacOS Data Mining Pytorch Honors &amp; Awards 全国高中数学联赛三等奖 全国大学生数学竞赛安徽赛区三等奖 安徽省程序设计竞赛二等奖 安徽省大数据技术与应用竞赛冠军 安徽省三创赛二等奖 合肥工业大学一等奖学金和三好学生等 合肥工业大学优秀毕业生,安徽省优秀毕业生 TODO the implement of MachineLearning In Action read the Watermelon book and Statistical learning method"},{"title":"categories","date":"2019-01-04T08:32:33.441Z","updated":"2019-01-04T08:32:33.441Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"R-CNN系列目标检测网络解析","slug":"RCNN系列目标检测网络解析","date":"2019-08-13T12:44:43.000Z","updated":"2019-08-13T13:23:41.545Z","comments":true,"path":"2019/08/13/RCNN系列目标检测网络解析/","link":"","permalink":"http://yoursite.com/2019/08/13/RCNN系列目标检测网络解析/","excerpt":"r-cnn:https://arxiv.org/pdf/1311.2524.pdffast r-cnn: https://arxiv.org/pdf/1504.08083.pdffaster r-cnn : https://arxiv.org/pdf/1506.01497.pdf 起源目标检测问题的起源:最初受到传统计算机视觉方法启发，使用滑动窗口检测器+SVM等分类器。但是有个问题:窗口的大小难以确定，因为物体是大小多样的。使用深度学习做目标检测的比较早期的方法就是R-CNN。","text":"r-cnn:https://arxiv.org/pdf/1311.2524.pdffast r-cnn: https://arxiv.org/pdf/1504.08083.pdffaster r-cnn : https://arxiv.org/pdf/1506.01497.pdf 起源目标检测问题的起源:最初受到传统计算机视觉方法启发，使用滑动窗口检测器+SVM等分类器。但是有个问题:窗口的大小难以确定，因为物体是大小多样的。使用深度学习做目标检测的比较早期的方法就是R-CNN。 R-CNN(Region convolutional neural network)流程输入一张图片，使用selective search（根据图像特征） 方法来提取region proposal （区域建议窗口），大约2000个左右，然后将 提取出来的2000个窗口 resize到统一尺寸，来符合CNN的输入，分别丢入CNN网络，然后用设计好的CNN的网络来提取特征，然后在最后加上SVM分类和BBox回归。 缺点需要对2000个proposal region逐个做CNN提取、分类、预测，很慢，而且有大量重复计算. 可以考虑的改进方案： 从窗口角度： 合理地选择窗口，减少运算量，提高运算效率 从网络结构的角度： 比如使用VGG16 ，resnet inception 等网络，来提高特征提取的精度和速度 Fast R-CNN流程先做SS，选出2000个窗口，但是不切出来，然后对原图整个做CNN提取特征，然后在CNN输出的特征图中按照2000个窗口的位置来切割，与之前先提取窗口，然后对每个窗口做CNN特征提取的效果是一样的。但是Fast-Rcnn只需要对大图做一次CNN，而RCNN需要对2000个小图分别做CNN，运算量比较大。另一个是用softmax来替换SVM，然后最后训练是使得multi-loss下降，multi-loss 包括bbox回归损失和分类损失。 改进(相对于R-CNN) 先使用卷积网络对图像进行特征提取，然后共享这个提取出来的feature map 因为使用SS提取的区域大小是不固定的，所以经过特征抽取网络后提取出来的feature map大小是不相同的，所以在特征抽取到分类回归层中间加上了ROI pooling网络结构，用于将不同大小的feature map分解成统一尺寸的特征(ROI pooling 的思想借鉴于 SPP-Net)。 使用softmax替换了SVM多分类器 缺点 使用SS的方法来提取2000个region开销太大，成为优化瓶颈，能否使用神经网络来寻找目标 Faster R-CNN 流程提出RPN网络（region proposal network）用于提取region，先在每个点找9个如图所示的anchor box 完整流程图","categories":[],"tags":[{"name":"Object Detection","slug":"Object-Detection","permalink":"http://yoursite.com/tags/Object-Detection/"},{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://yoursite.com/tags/Deep-Learning/"}]},{"title":"“好而不同”的集成学习","slug":"解析集成学习","date":"2019-08-11T05:58:31.000Z","updated":"2019-08-13T12:44:12.778Z","comments":true,"path":"2019/08/11/解析集成学习/","link":"","permalink":"http://yoursite.com/2019/08/11/解析集成学习/","excerpt":"集成学习（Ensemble Learning）概述集成学习的思想就是组合多个弱学习器，得到一个强学习器。但注意，弱学习器不能太弱，比如在分类中，弱学习器的准确率最少要达到50%.","text":"集成学习（Ensemble Learning）概述集成学习的思想就是组合多个弱学习器，得到一个强学习器。但注意，弱学习器不能太弱，比如在分类中，弱学习器的准确率最少要达到50%. “好而不同”集成学习强调”好而不同”，这里的”好”是指学习器效果还不错，只要不太差就行；这里的”不同”指的是这些要集成的学习器各自在不同的方面还不错，集合在一起就能互相弥补，正所谓“三个臭皮匠赛过诸葛亮”. 针对每个学习器的个体，在选择弱学习器的时候，倾向于选择神经网络(Neural Network)，决策树(Decision Tree)这种类型(给定数据训练出来的学习器有一定随机性)，而不是选择SVM,朴素贝叶斯这种(对给定数据训练出来的学习器相差不大的学习器)。举个栗子，因为如果选择SVM可能学出的多个学习器是相似的，集成在一起就取不到更好的效果。但是如果选择决策树，训练出来的多个学习器很可能分支决策很不相同。所以多个”各有所长”的弱学习器就有机会集成为一个强学习器。另一方面，集成学习主要分为两种策略，Bagging和Boosting，在Bagging中首先是进行对给定数据进行N次Bootstrap抽样（又放回的抽样），然后训练N个弱学习器，这也体现了”不同”.在Boosting中，得到的多个学习器是在不同权重的数据样本下训练得到的，所以也是各有”不同”。","categories":[],"tags":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://yoursite.com/tags/Machine-Learning/"},{"name":"Ensemble Learning","slug":"Ensemble-Learning","permalink":"http://yoursite.com/tags/Ensemble-Learning/"}]},{"title":"深入理解ResNet","slug":"深入理解ResNet","date":"2019-08-09T10:55:56.000Z","updated":"2019-08-14T01:43:12.115Z","comments":true,"path":"2019/08/09/深入理解ResNet/","link":"","permalink":"http://yoursite.com/2019/08/09/深入理解ResNet/","excerpt":"ResNet能够work的主要原因: 作者说残差结构是为了解决网络退化的问题，作者猜测","text":"ResNet能够work的主要原因: 作者说残差结构是为了解决网络退化的问题，作者猜测 We conjecture that the deep plain nets may have exponentially low convergence rates, which impact the reducing of the training error. The reason for such optimization difficulties will be studied in the future. 认为 deep plain nets 可能有指数级低收敛率，限制了训练误差的进一步降低。他简单地比较了残差结构和常规结构在求解本征映射(identity map)时的优化难度，显然求解 F(x)=0 比求解 H(x) = x 容易得多也就是说能够更好地学习到差分特征，相当更容易学习到残差的那一部分。(这是ResNet有效地最主要原因) 残差网络对数据波动更敏感 我们回到设计 ResNet 的初衷： 为了解决深度网络的 退化 问题 。该问题的直接表现形式为： 深度网络在的训练误差比浅层网络高，无法做到使深层网络在训练数据集上“ 过拟合 ”。那么如何做到“过拟合”呢？ 答案就是我们需要使网络对数据波动更敏感，尽可能地去准确描述数据。而残差网络就是这样的一种网络结构。假设某几层 layer 要学习的函数 H(x) 如紫线所示，红色点表示采样点，对应一个数据样本。 在ResNet 中激活函数全部采用 ReLU， 我们知道 采用 ReLU 的网络是局部空间的线性网络的组合。对于数据点（5,5.1），即我们的 input 为5， 期望输出为5.1，假设为 plain network， 我们在 x =5 的附近，学习到的线性参数值为 w = 5.1/5 , 若数据点变成（5,5.2），我们仍可以用 w= 5.1/5 的线性网络近似，因为此时网络输出 5.1 与理想值 5.2 只相差 2% 而已. 所以在 plain net 中，网络对 数据不敏感。 数据的波动指的是相对对角线 y= x 的波动, 残差网络的思想是：我们用 y= x 先去粗略拟合数据， “波动”也即“拟合残差”就交给 weight layer 去拟合。数据点（5,5.1）对应的残差为（5,0.1），此时假设学习到的参数为 w=0.1/5 。同样地，若数据点变成（5,5.2），对应的残差为（5,0.2）。显然地，我们不可以用 0.1/5 近似了，因为若用0.1/5 近似，网络输出 0.1 和 0.2 相差了100%。网络需要调整 w 的值，以尽可能精确地描述残差。所以综上所述，残差网络对数据变得敏感，也即对“数据波动更敏感”，更容易做到“过拟合”。 集成学习思想，ResNet是由很多条路径集成学习得到的，对于每个block如果残差为0就退化为直连。如果所有resblock的残差都是0，那么就退化成VGG网络。 特征表示，跳层连接使得表达特征更加丰富，比如说前面网络层的浅层特征能够和深层的特征融合。2017年的DenseNet网络有类似的设计。 缓解梯度消失问题，梯度能够直接传到skip connection前面的网络层（不是主要原因，作者说这个梯度消失的问题使用Batch Normalization就能解决，但resNet确实有缓解梯度消失的效果） 参考https://zhuanlan.zhihu.com/p/54289848https://www.jianshu.com/p/ca6bee9eb888","categories":[],"tags":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://yoursite.com/tags/Deep-Learning/"},{"name":"ResNet","slug":"ResNet","permalink":"http://yoursite.com/tags/ResNet/"},{"name":"CNN","slug":"CNN","permalink":"http://yoursite.com/tags/CNN/"}]},{"title":"Batch Normalization解析","slug":"Batch-Normalization","date":"2019-08-08T08:47:43.000Z","updated":"2019-08-09T02:51:45.517Z","comments":true,"path":"2019/08/08/Batch-Normalization/","link":"","permalink":"http://yoursite.com/2019/08/08/Batch-Normalization/","excerpt":"论文链接 : https://arxiv.org/abs/1502.03167","text":"论文链接 : https://arxiv.org/abs/1502.03167 介绍Batch Normalization 是批归一化，用来解决神经网络中协方差偏移问题，就是每一层的分布很混乱，除非从第一层开始每一层的输入的分布都很有效，否则就得不到好的效果。如下图所示。 所以，为了解决这个问题，我们引入了Batch Normalization. 介绍一下在机器学习中，是如何做feature scaling，因为输入的不同变量分布不同，比如说x1可能是代表房子的房间数量，x2代表房子的大小多少平方，那么x2和x1很显然不属于统一量纲，所以要做归一化，如下图所示。 原理顾名思义，Batch Normalization是对一个batch的数据做处理， 求均值 除以标准差 仿射变换（可选）（有时候需要把均值和方差调整到某些范围时可以加上） 然后将Batch Normalization的结果送给激活函数层，才能比较好的发挥激活函数的作用。 举个栗子，比如像Sigmoid函数，如果不做Batch Normalization，可能会导致输入分布在两边（就是不集中在[-1，1] ），梯度就很小，链式相乘之后就会接近于0，做了Batch Normalization，把输入集中在0附近，使得激活函数更好地发挥作用。 pytorch实现pytorch api1234567891011torch.nn.BatchNorm1d(num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)torch.nn.BatchNorm2d(num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) affine是仿射，track_running_stats是保留在训练时候的数据方差和均值，从而运用到测试中，因为在测试中是不方便计算方差和均值的。要注意在训练的时候选择model.train()模式在测试的时候选择model.eval()模式，这样Batch Normalization中的参数才会固定。 知乎上有个BN为什么能够解决梯度消失和爆炸问题的回答写的很好:https://www.zhihu.com/question/38102762/answer/391649040","categories":[],"tags":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://yoursite.com/tags/Deep-Learning/"}]},{"title":"经典CNN结构解析与实现","slug":"CNN-Network","date":"2019-08-02T01:36:03.000Z","updated":"2019-08-08T11:16:24.928Z","comments":true,"path":"2019/08/02/CNN-Network/","link":"","permalink":"http://yoursite.com/2019/08/02/CNN-Network/","excerpt":"实现代码地址：Github","text":"实现代码地址：Github 目录 AlexNet VGG Google Inception Net ResNet DenseNet MobileNet Shuffle Net AlexNet 首次使用CNN组建的深度网络在ImageNet上达到最好效果 它使用Relu 激活函数代替了传统的激活函数(Sigmoid/Tanh) 使用Dropout 解决过拟合问题 计算量较大 VGG VGG使用连续的几个3*3卷积核代替AlexNet中较大的卷积核，减少计算量。 VGG Net中采用的卷积核是非常一致的，全都是3*3的filter VGG 分为4-5个block，每个block包含若干个3*3的卷积层和一个2*2的MaxPooling层所以得到的conv4_3是16倍的下采样的feature map Inception Net 设计了Inception Block，采用了不同尺度的filter，size为1*1,3*3,5*5，获得了不同scale的特征，具有对不同尺度特征的提取能力，而且还通过1*1的卷积层来大大降低运算。 在卷积层结束后，使用全局AveragePooling，避免使用全连接层 ResNet 在VGG网络后，研究人员发现仅仅堆叠越来越多层的CNN 或 全连接层等是无法再提高准确率，主要原因就是梯度消失的问题，因为在多层神经网络中，梯度传到最前面的网络层就非常接近0了，导致前面网络层的参数更新很慢。于是提出ResNet去解决这个梯度消失的问题。 ResNet主要是设计了一个ResBlock。ResBlock使用skip connect 跳层连接，使得梯度能够有效地回传，从而参数得以更新，才敢设计比VGG深很多的网络。 DenseNet 设计思路与ResNet非常相似，但实际上一个很大的区别是，它是做多channel的特征的拼接，而ResNet是做求和计算 DenseNet主要包含两个模块，DenseBlock和Transition层，每个DenseBlock的内部是将第N层之前的feature map都经过卷积处理到固定shape拼接到第N层，Transition作为缓冲层是将维度进行降低，减少计算量 优点：梯度消失问题得到改善，特征复用，使用了multi-scale的特征,参数少，因为特征图的channel不像之前的那么多 MobileNet 解决深度学习网络移动设备上的运行速度问题，提出的高效的网络，在模型大小显著减少的情况下，对准确率不造成太大影响 使用 depthwise separable convolution 代替传统卷积网络。 depthwise separable convolution depthwise卷积 对输入的D*D*M的M个通道，每个通道使用一个filter进行卷积，即使用M个卷积核分别对M个通道进行卷积，得到feature mapD*D*M pointwise卷积 对经过上面步骤得到的feature mapD*D*M的每个cell(shape为 1*1*M) 使用1*1*M*N卷积核进行卷积 SqueezeNetShuffle Net","categories":[],"tags":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://yoursite.com/tags/Deep-Learning/"},{"name":"Image Classification","slug":"Image-Classification","permalink":"http://yoursite.com/tags/Image-Classification/"},{"name":"Feature Extract","slug":"Feature-Extract","permalink":"http://yoursite.com/tags/Feature-Extract/"}]},{"title":"《You Only Look Once》YOLOv1论文笔记","slug":"YOLOv1","date":"2019-08-01T08:25:01.000Z","updated":"2019-08-02T01:18:14.441Z","comments":true,"path":"2019/08/01/YOLOv1/","link":"","permalink":"http://yoursite.com/2019/08/01/YOLOv1/","excerpt":"YOLO v1论文:《You Only Look Once: Uniﬁed, Real-Time Object Detection》论文地址：http://www.arxiv.org/pdf/1506.02640.pdf","text":"YOLO v1论文:《You Only Look Once: Uniﬁed, Real-Time Object Detection》论文地址：http://www.arxiv.org/pdf/1506.02640.pdf 简介作者提出把目标检测任务当做回归任务来做，用一个神经网络来完成bbox(bounding box)以及class probabilities(类别概率)的回归，因为网络是单个完整的，不同于Faster R-CNN是分为RPN(Region Proposal Network,区域建议网络，用来生成一些proposal，输给后续的回归网络)和回归网络。所以YOLO网络是可以端到端的训练。 网络结构 YOLO系统流程 输入图片img resize到指定尺寸 通过预先设计好的多层CNN(一般包括特征抽取的VGG，以及回归层等) 根据回归层输出的坐标和置信度confidence来对proposal进行筛选 主要的网络结构如图如上图所示，输入一个图片，resize到448*448的，经过N多卷积网络层得到7*7*30的feature map 图片源于知乎用户这个维度30的意义如下图所示，包括confidence*2,(x1,y1)(x2,y2)四个坐标*2,20个类别概率(哪个概率大就是哪一类，用softmax实现)，每一个30维的vector代表一个7*7的feature map 的每一个cell里面的信息。 置信度在训练时计算如上图所示，Pr(object)就是选择一个cell中与训练样本ground truth的IOU大的那个proposal为1，另一个为0，所以这个置信度即为IOU或0。 Loss Function 如图所示，损失函数包括三部分：坐标回归损失、分类损失和置信度损失。坐标回归损失只是针对那些被认定为包含object的proposal才进行计算，对于没有检测到object的proposal不需要坐标回归的loss，分类损失也是检测到object的proposal要计算。还有一个置信度误差，不管有没有检测到object都要去计算。 Problem 每个vector的30维中只有一个20维的class probability ，但是有两个5维(4个坐标+1个置信度)向量，这代表了实际上7*7的feature map中的每一个单元都只能预测一个object，那么对于每个object为什么要使用两个回归向量呢？是为了精确地解决回归问题，最后这两个回归出来的proposal最多保留IOU大的那一个。","categories":[],"tags":[{"name":"Object Detection","slug":"Object-Detection","permalink":"http://yoursite.com/tags/Object-Detection/"},{"name":"Computer Vision","slug":"Computer-Vision","permalink":"http://yoursite.com/tags/Computer-Vision/"},{"name":"Notes","slug":"Notes","permalink":"http://yoursite.com/tags/Notes/"}]},{"title":"机器学习西瓜书第一章","slug":"ML_1","date":"2019-07-16T11:51:36.000Z","updated":"2019-07-17T02:20:12.202Z","comments":true,"path":"2019/07/16/ML_1/","link":"","permalink":"http://yoursite.com/2019/07/16/ML_1/","excerpt":"第一章 绪论归纳偏好 （挑选假设函数的基准） 一般根据“奥卡姆剃刀”原则，也就是选择最简单的假设函数。 如无必要，勿增实体。 比如说给定有限训练集，有很多假设都能使得结果与有限训练集标签相似，这时候需要一个准则来在这个庞大的假设空间中选择假设进行启发，就是奥卡姆剃刀准则。","text":"第一章 绪论归纳偏好 （挑选假设函数的基准） 一般根据“奥卡姆剃刀”原则，也就是选择最简单的假设函数。 如无必要，勿增实体。 比如说给定有限训练集，有很多假设都能使得结果与有限训练集标签相似，这时候需要一个准则来在这个庞大的假设空间中选择假设进行启发，就是奥卡姆剃刀准则。 没有归纳偏执或者归纳偏执太宽泛会导致 Overfitting，限制过大的归纳偏执也是有问题的，如果数据本身并不是线性的，强行用线性函数去做回归通常并不能得到好结果。 “”没有免费的午餐“ No Free Lunch Theorem定理: 总误差与学习算法无关，它们的期望性能相同。（NFL前提：所有“问题”出现的机会相同，或所有问题同等重要，但实际情形并不是这样） NFL定理最重要的寓意：脱离具体问题，空泛的谈论“什么学习算法更好”毫无意义。因为若考虑所有潜在的问题，则所有学习算法都一样好，要谈论算法的相对优劣，必须要针对具体的学习问题，在某些问题上表现好的学习算法，在另一些问题上却可能不尽如人意。学习算法自身的归纳偏好与问题是否相配，往往会起到决定性的作用。 参考: https://www.jianshu.com/p/b26b85fac9ad","categories":[],"tags":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://yoursite.com/tags/Machine-Learning/"},{"name":"西瓜书","slug":"西瓜书","permalink":"http://yoursite.com/tags/西瓜书/"}]},{"title":"Hello World","slug":"hello-world","date":"2018-10-24T07:44:41.109Z","updated":"2019-08-08T11:16:36.817Z","comments":true,"path":"2018/10/24/hello-world/","link":"","permalink":"http://yoursite.com/2018/10/24/hello-world/","excerpt":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}