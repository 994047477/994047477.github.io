{"meta":{"title":"LiXuan's blog","subtitle":"Deeplearning|MachineLearning|ComputerVision","description":"Deeplearning|MachineLearning|ComputerVision","author":"leexuan","url":"http://yoursite.com"},"pages":[{"title":"about","date":"2019-07-16T11:50:27.752Z","updated":"2019-07-16T11:50:27.748Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"ResumeContact gmail: lixuan980726(AT)gmail.comEducation Fudan University 2019.9 - 2022.6 M.S. in Software Engineering Research on computer vision and deeplearning Hefei University of Technology 2015.9 - 2019.6 B.S. in Computer Science GPA:3.75/4.3 , Rank: 7/196 Skills English – CET4,CET6 Python Computer Vision(Object detection) DeepLearning MachineLearning Hadoop,Hive (simple big data processing ) Web Spider Simple website building (use JSP and Servlet) Linux/MacOS Data Mining pytorch/tensorflow/keras learning…. Honors &amp; Awards 全国高中数学联赛三等奖 全国大学生数学竞赛安徽赛区三等奖 安徽省程序设计竞赛二等奖 安徽省大数据技术与应用竞赛冠军 安徽省三创赛二等奖 合肥工业大学一等奖学金和三好学生等 合肥工业大学优秀毕业生,安徽省优秀毕业生 Finish OCR Graduation project — Use CTPN and Tesseract network TODO the implement code of MachineLearning In Action read the Watermelon book and Statistical learning method"},{"title":"404","date":"2018-10-24T07:55:18.000Z","updated":"2018-10-24T07:55:18.744Z","comments":true,"path":"404/index.html","permalink":"http://yoursite.com/404/index.html","excerpt":"","text":""},{"title":"search","date":"2018-10-24T07:55:10.000Z","updated":"2018-10-24T07:55:10.868Z","comments":true,"path":"search/index.html","permalink":"http://yoursite.com/search/index.html","excerpt":"","text":""},{"title":"categories","date":"2019-01-04T08:32:33.441Z","updated":"2019-01-04T08:32:33.441Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2019-01-04T08:25:56.849Z","updated":"2019-01-04T08:25:56.849Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"机器学习西瓜书第一章","slug":"ML_1","date":"2019-07-16T11:51:36.000Z","updated":"2019-07-16T11:59:13.389Z","comments":true,"path":"2019/07/16/ML_1/","link":"","permalink":"http://yoursite.com/2019/07/16/ML_1/","excerpt":"第一章 绪论 归纳偏好 （挑选假设函数的基准） 一般根据“奥卡姆剃刀”原则，也就是选择最简单的假设函数。 如无必要，勿增实体。 比如说给定有限训练集，有很多假设都能使得结果与有限训练集标签相似，这时候需要一个准则来在这个庞大的假设空间中选择假设进行启发，就是奥卡姆剃刀准则。","text":"第一章 绪论 归纳偏好 （挑选假设函数的基准） 一般根据“奥卡姆剃刀”原则，也就是选择最简单的假设函数。 如无必要，勿增实体。 比如说给定有限训练集，有很多假设都能使得结果与有限训练集标签相似，这时候需要一个准则来在这个庞大的假设空间中选择假设进行启发，就是奥卡姆剃刀准则。 没有归纳偏执或者归纳偏执太宽泛会导致 Overfitting，限制过大的归纳偏执也是有问题的，如果数据本身并不是线性的，强行用线性函数去做回归通常并不能得到好结果。 “”没有免费的午餐“ No Free Lunch Theorem定理: 总误差与学习算法无关，它们的期望性能相同。（NFL前提：所有“问题”出现的机会相同，或所有问题同等重要，但实际情形并不是这样） NFL定理最重要的寓意：脱离具体问题，空泛的谈论“什么学习算法更好”毫无意义。因为若考虑所有潜在的问题，则所有学习算法都一样好，要谈论算法的相对优劣，必须要针对具体的学习问题，在某些问题上表现好的学习算法，在另一些问题上却可能不尽如人意。学习算法自身的归纳偏好与问题是否相配，往往会起到决定性的作用。 参考: https://www.jianshu.com/p/b26b85fac9ad","categories":[],"tags":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://yoursite.com/tags/Machine-Learning/"},{"name":"西瓜书","slug":"西瓜书","permalink":"http://yoursite.com/tags/西瓜书/"}]},{"title":"Hello World","slug":"hello-world","date":"2018-10-24T07:44:41.109Z","updated":"2018-10-24T07:44:41.109Z","comments":true,"path":"2018/10/24/hello-world/","link":"","permalink":"http://yoursite.com/2018/10/24/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}