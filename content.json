{"meta":{"title":"LiXuan's blog","subtitle":"Deeplearning|MachineLearning|ComputerVision","description":"Deeplearning|MachineLearning|ComputerVision","author":"leexuan","url":"http://yoursite.com"},"pages":[{"title":"404","date":"2018-10-24T07:55:18.000Z","updated":"2018-10-24T07:55:18.000Z","comments":true,"path":"404/index.html","permalink":"http://yoursite.com/404/index.html","excerpt":"","text":""},{"title":"about","date":"2021-03-27T04:09:27.675Z","updated":"2021-03-27T04:09:27.675Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"ResumeSelf Introduction 我是leexuan，1998年7月出生于安徽芜湖，目前复旦大学MMDB实验室一年级硕士在读，本科毕业于合肥工业大学计算机专业，从大三开始学习大数据技术、机器学习、深度学习，保研到复旦大学攻读硕士。 我是一名数据挖掘竞赛爱好者，在闲暇时间会去参与一些竞赛。 读研期间，我将会抽空去更新博客，将所学的一些知识(论文、书籍、竞赛等)进行总结归纳。 我是一个兴趣非常广泛的人，我会去学习我感兴趣的很多的方向，如果你和我需要和我交流（包括竞赛、科研、编程开发、求职等）或者是博客里有些观点表述有误，可以通过邮箱联系我，请多多指教！ Contact Mail: xuanli19(AT)mail.fudan.edu.cn EducationFudan University 2019.9 - 2022.6 M.S. in Software Engineering Research on Deep Learning | Machine Learning Hefei University of Technology 2015.9 - 2019.6 B.S. in Computer Science GPA:3.75/4.3 , Rank: 3/196 Skills English – CET6 Python &gt; C++ &gt; JAVA &gt; Shell Latex|MarkDown Computer Vision(Object Detection,OCR) Deep Learning(CNN|RNN|GAN) Machine Learning(LR|SVM|GBDT|NB|KNN|K-Means|PCA) NLP (Word Embedding– word2vec ,TextCNN etc.. ) Hadoop,Hive (simple big data processing ) Web Spider Website building (use JSP and Servlet) Linux|MacOS Data Mining Pytorch &gt; Tensorflow Docker Search Engine (Inverted Index) Recommender System ( ItemCF,UserCF,LFM,FM ) Honors &amp; Awards 2014年全国高中数学联赛三等奖 2016年全国大学生数学竞赛安徽赛区三等奖 2017年安徽省程序设计竞赛二等奖 2017年安徽省大数据技术与应用竞赛冠军 2017年安徽省三创赛二等奖 合肥工业大学一等奖学金和三好学生等 合肥工业大学优秀毕业生,安徽省优秀毕业生 Competition [芒果TV视频推荐算竞赛] rank:4/540 [PAKDD2020 阿里巴巴智能运维算法大赛] rank: 12/1173 My Projects hotel-management-system(DataBase Project) web spider Recommended resources 李宏毅的机器学习、深度学习、GAN(http://speech.ee.ntu.edu.tw/~tlkagk) Andrew NG 机器学习与 deeplearning.ai 深度学习 机器学习基石、机器学习技法 (林轩田) 周志华 《机器学习》,李航 《统计学习方法》,PRML,邱锡鹏《神经网络深度学习》"},{"title":"categories","date":"2020-03-20T02:15:16.370Z","updated":"2019-01-04T08:32:33.000Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"","date":"2020-03-26T05:51:36.763Z","updated":"2020-03-26T05:51:36.763Z","comments":true,"path":"downloads/index.html","permalink":"http://yoursite.com/downloads/index.html","excerpt":"","text":"Sharing && Presentation 一些论文和技术分享 Docker入门 FOTS (FOTS: Fast Oriented Text Spotting with a Unified Network) MapReduce"},{"title":"search","date":"2018-10-24T07:55:10.000Z","updated":"2018-10-24T07:55:10.000Z","comments":true,"path":"search/index.html","permalink":"http://yoursite.com/search/index.html","excerpt":"","text":""},{"title":"tags","date":"2020-03-20T02:15:16.367Z","updated":"2019-01-04T08:25:56.000Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"docker入门","slug":"docker-study","date":"2020-03-20T02:06:41.000Z","updated":"2020-03-20T09:06:31.333Z","comments":true,"path":"2020/03/20/docker-study/","link":"","permalink":"http://yoursite.com/2020/03/20/docker-study/","excerpt":"安装docker配置国内镜像源 比如申请阿里云的加速镜像地址","text":"安装docker配置国内镜像源 比如申请阿里云的加速镜像地址 docker 指令12345678910111213141516171819202122232425262728293031323334- `docker images` + `docker images -a` + `docker images -aq ` - `docker search 镜像名 ` 在dockerhub 中寻找镜像- `docker pull 镜像名` 在镜像源Pull镜像到本地- `docker rmi ` 删除镜像 * `docker rmi -f 镜像ID` 删除指定镜像 * `docker rmi -f $(docker images -qa)` 删除所有镜像- `docker run ` 新建并启动容器 * `docker run -i -t imageid` 交互式登入容器，并进入伪终端(-i 和 -t 可以一起写成 -it ) * `docker run -it --name 新命名 imageid` 给登入容器取个名字 * `docker run -d 镜像名` 后台启动容器 - `docker ps` 当前运行的容器- docker 退出 * `exit` 关闭容器并退出 * `ctrl+P+Q` 容器不停止退出- docker 启动容器 * `docker start 容器ID`- docker 重启容器 * `docker restart` - docker 停止容器 * `docker stop 容器ID` 一般停止 * `docker kill 容器ID` 强制停止- docker 删除容器 * `docker rm 容器ID` (rmi 是删除镜像,rm是删除容器) * 删除多容器 `docker rm -f $(docker ps -aq)` * 等价于 `docker ps -aq | xargs docker rm `- docker 容器信息 * `docker top 容器ID` 容器正在运行的进程 * `docker inspect 容器ID` 容器内部细节json形式返回 * 与正在运行的容器进行交互 - `docker exec -it 容器ID 执行的指令` 比如说可以直接在外面命令容器执行指令而不需要登进去,`ls -l`、 `python demo.py` ,也可以/bin/bash 登入 - `docker attach 容器ID ` 登进正在运行的容器 - `docker cp 容器ID:/tmp.yum.log /home` 将容器中的文件拷到宿主机","categories":[],"tags":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/tags/docker/"}]},{"title":"改进版梯度下降","slug":"改进版梯度下降","date":"2020-01-30T02:34:16.000Z","updated":"2020-01-30T02:34:16.000Z","comments":true,"path":"2020/01/30/改进版梯度下降/","link":"","permalink":"http://yoursite.com/2020/01/30/%E6%94%B9%E8%BF%9B%E7%89%88%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"机器学习技法","slug":"机器学习技法","date":"2020-01-22T06:49:34.000Z","updated":"2020-01-22T06:49:34.000Z","comments":true,"path":"2020/01/22/机器学习技法/","link":"","permalink":"http://yoursite.com/2020/01/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8A%80%E6%B3%95/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"Linux定时任务-crontab","slug":"Linux-定时任务","date":"2019-12-18T04:07:42.000Z","updated":"2020-03-26T03:20:01.686Z","comments":true,"path":"2019/12/18/Linux-定时任务/","link":"","permalink":"http://yoursite.com/2019/12/18/Linux-%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1/","excerpt":"背景之前在把爬虫部署到实验室的服务器上，让它不间断的爬取，但是第二天早上发现爬虫终止了，仔细一看才发现是网络异常，原因是复旦的校网每天早上3：00都要断掉所有连接。所以我就要用这个crontab指令让它在3:01的时候把网络给连上。","text":"背景之前在把爬虫部署到实验室的服务器上，让它不间断的爬取，但是第二天早上发现爬虫终止了，仔细一看才发现是网络异常，原因是复旦的校网每天早上3：00都要断掉所有连接。所以我就要用这个crontab指令让它在3:01的时候把网络给连上。 通过crontab 命令，我们可以在固定的间隔时间执行指定的系统指令或 shell script脚本。时间间隔的单位可以是分钟、小时、日、月、周及以上的任意组合。这个命令非常适合周期性的日志分析或数据备份等工作。 操作流程执行 crontab -e 编辑当前用户的crontab文件内容， m h dom mon dow command01 3 * * * /etc/profile;/bin/bash /home/lixuan/tmp/auto_login.sh 第1列分钟0～59 第2列小时0～23（0表示子夜） 第3列日1～31 第4列月1～12 第5列星期0～7（0和7表示星期天） 第6列要运行的命令 格式如上所示，就是设置的每天的3:01执行/home/lixuan/tmp/auto_login.sh脚本，这个脚本就是连接校网的脚本。 Reference[1] https://linuxtools-rst.readthedocs.io/zh_CN/latest/tool/crontab.html","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"}]},{"title":"Tmux 简单使用","slug":"Tmux-简单使用","date":"2019-12-18T04:07:03.000Z","updated":"2020-03-26T04:03:56.287Z","comments":true,"path":"2019/12/18/Tmux-简单使用/","link":"","permalink":"http://yoursite.com/2019/12/18/Tmux-%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/","excerpt":"背景在跑深度学习程序的时候，总不能一直等着这个进程结束再干活吧，所以我们就需要让这个进程在后台运行，我们可以在前台干其他活。大四的时候在实验室被突突突同学安利了Tmux，当时一直用的是nohup，没有体验到差距。","text":"背景在跑深度学习程序的时候，总不能一直等着这个进程结束再干活吧，所以我们就需要让这个进程在后台运行，我们可以在前台干其他活。大四的时候在实验室被突突突同学安利了Tmux，当时一直用的是nohup，没有体验到差距。 大四暑假的时候，就体验了一下Tmux的终端复用，真香!!! 简单介绍Tmux 是一款终端复用软件， Mac 安装 Tmux brew install tmux Tmux 使用 tmux ls 展示所有的tmux任务 tmux at -t 任务名 用来恢复指定任务窗口 tmux a进入最近的一个的任务中 ctrl+b d 将当前tmux任务拉到后台运行 ctrl+b s 弹出当前tmux中所有的任务列表，可以上下选择进入 tmux new -s 任务名 创建指定任务名的任务 tmux kill-session -t 任务名 删除指定任务 tmux kill-server 关闭服务器，所有的会话都将关闭 常用方法 有了Tmux 之后，就是先new一个train session tmux new -s train,然后挂起control +B +D,这样不影响服务器正常使用，也能隔一段时间进入这个tmux终端tmux -at -t train看看模型训练情况。&gt;_&lt; ….. Reference http://louiszhai.github.io/2017/09/30/tmux/ http://cenalulu.github.io/linux/tmux/","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"Tmux","slug":"Tmux","permalink":"http://yoursite.com/tags/Tmux/"}]},{"title":"线性回归正则化","slug":"线性回归正则化","date":"2019-10-23T10:18:44.000Z","updated":"2020-01-03T13:52:24.000Z","comments":true,"path":"2019/10/23/线性回归正则化/","link":"","permalink":"http://yoursite.com/2019/10/23/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%AD%A3%E5%88%99%E5%8C%96/","excerpt":"占坑，有时间再更 L1 和L2 正则化的原理","text":"占坑，有时间再更 L1 和L2 正则化的原理","categories":[],"tags":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://yoursite.com/tags/Machine-Learning/"}]},{"title":"朴素贝叶斯","slug":"NaiveBayes","date":"2019-10-23T10:17:31.000Z","updated":"2020-01-03T13:52:48.000Z","comments":true,"path":"2019/10/23/NaiveBayes/","link":"","permalink":"http://yoursite.com/2019/10/23/NaiveBayes/","excerpt":"占坑，有时间再更","text":"占坑，有时间再更","categories":[],"tags":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://yoursite.com/tags/Machine-Learning/"}]},{"title":"PCA","slug":"PCA","date":"2019-10-22T03:19:59.000Z","updated":"2020-01-03T13:55:12.000Z","comments":true,"path":"2019/10/22/PCA/","link":"","permalink":"http://yoursite.com/2019/10/22/PCA/","excerpt":"PCA（Principal Component Analysis） 流程 原理 正交化分解","text":"PCA（Principal Component Analysis） 流程 原理 正交化分解 Reference[1] https://zhuanlan.zhihu.com/p/21580949","categories":[],"tags":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://yoursite.com/tags/Machine-Learning/"}]},{"title":"机器学习评测指标","slug":"metrics","date":"2019-10-08T06:27:18.000Z","updated":"2020-03-26T05:53:33.999Z","comments":true,"path":"2019/10/08/metrics/","link":"","permalink":"http://yoursite.com/2019/10/08/metrics/","excerpt":"机器学习评测指标与工具 ROC曲线 AUC值","text":"机器学习评测指标与工具 ROC曲线 AUC值 PR曲线 MAP值 混淆矩阵 Q&amp;AQ: 为什么ROC曲线不受样本不均衡问题的影响? A: 参考 https://blog.csdn.net/songyunli1111/article/details/82285266","categories":[],"tags":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://yoursite.com/tags/Machine-Learning/"}]},{"title":"pix2pix论文阅读","slug":"pix2pix","date":"2019-09-22T03:21:40.000Z","updated":"2019-09-22T07:18:53.000Z","comments":true,"path":"2019/09/22/pix2pix/","link":"","permalink":"http://yoursite.com/2019/09/22/pix2pix/","excerpt":"论文:《Image-to-Image Translation with Conditional Adversarial Networks》 概述pix2pix网络基于conditional gan改进，CGAN的生成器网络是输入噪声和条件y，而pix2pix生成器网络是只有一个输入Image，然后经过生成网络(类似U-net等网络)，生成一张image.","text":"论文:《Image-to-Image Translation with Conditional Adversarial Networks》 概述pix2pix网络基于conditional gan改进，CGAN的生成器网络是输入噪声和条件y，而pix2pix生成器网络是只有一个输入Image，然后经过生成网络(类似U-net等网络)，生成一张image. 举个栗子，正因为网络结构的差异，这些网络可以完成不同的任务，比如普通的GAN，只给一堆二次元人物头像，然后让gan学习到从输入噪声生成出和原二次元头像训练图片风格很相似但是内容不一样的图片.对于CGAN，可以给输入条件label和对应的真实数据进行训练，比如使用Mnist数据集，将one-hot标签[0,1,0,0…]和数字1的图像一起送给生成器训练，其他的对应送给CGAN训练。不断迭代学习，最后能够给一个噪声和标签[0,0,1,0,0…]就能生成一个数字2的图像。pix2pix网络，主要是对图像做翻译，给定一对图片[a1,a2,a3…][b1,b2,b3…]送入pix2pix网络学习，生成器输入a1，生成出一个image，然后使用鉴别器和对应标签b1一起打分，经过不断地训练,最后就能完成图像翻译的工作，如下图效果所示。 参考[1] https://blog.csdn.net/weixin_38148834/article/details/95998627","categories":[],"tags":[{"name":"Image Translation","slug":"Image-Translation","permalink":"http://yoursite.com/tags/Image-Translation/"}]},{"title":"GBDT 与 XGBoost","slug":"xgboost","date":"2019-08-26T03:21:40.000Z","updated":"2019-08-26T03:22:25.000Z","comments":true,"path":"2019/08/26/xgboost/","link":"","permalink":"http://yoursite.com/2019/08/26/xgboost/","excerpt":"","text":"TODO","categories":[],"tags":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://yoursite.com/tags/Machine-Learning/"}]},{"title":"Single Shot Detector","slug":"ssd","date":"2019-08-26T03:21:27.000Z","updated":"2019-08-26T03:22:55.000Z","comments":true,"path":"2019/08/26/ssd/","link":"","permalink":"http://yoursite.com/2019/08/26/ssd/","excerpt":"","text":"TODO","categories":[],"tags":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://yoursite.com/tags/Deep-Learning/"},{"name":"Object Detection","slug":"Object-Detection","permalink":"http://yoursite.com/tags/Object-Detection/"}]},{"title":"object detection tutorial","slug":"object-detection-tutorial","date":"2019-08-17T12:51:46.000Z","updated":"2020-03-26T05:53:12.875Z","comments":true,"path":"2019/08/17/object-detection-tutorial/","link":"","permalink":"http://yoursite.com/2019/08/17/object-detection-tutorial/","excerpt":"OverFeat 提出将图像分类，目标检测分割等任务使用同一套网络做特征提取的思想，前面的几层网络特征抽取层可以公用，只需要改动最后面几层输出层即可，为后来很多的目标检测算法提供了改进思路","text":"OverFeat 提出将图像分类，目标检测分割等任务使用同一套网络做特征提取的思想，前面的几层网络特征抽取层可以公用，只需要改动最后面几层输出层即可，为后来很多的目标检测算法提供了改进思路 SSD FPNR-FCN: Object Detection via Region-based Fully Convolutional Networks 概述R-FCN 提出了position-sensitive score maps去解决平移不变性，而且可以轻易为R-FCN替换各种全卷积特征抽取网络(如ResNet等)，相比较Faster R-CNN系列，能够共享更多的运算，提升速度。 RetinaNet 主要贡献在于提出 Focal Loss，解决了类别不均衡问题(主要包括平衡easy sample 和 hard sample，以及True sample 和 False sample的权重)提高精度，解决了One-stage detector 精度不如 Two-stage detector的问题. SPPNet 首次提出使用roi pooling层，使得不同size的feature池化成统一scale，这样就不用再输入图片时进行resize处理了","categories":[],"tags":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://yoursite.com/tags/Deep-Learning/"},{"name":"Object Detection","slug":"Object-Detection","permalink":"http://yoursite.com/tags/Object-Detection/"}]},{"title":"YOLOv2/v3的改进","slug":"yolo","date":"2019-08-17T12:19:02.000Z","updated":"2019-08-17T13:01:52.000Z","comments":true,"path":"2019/08/17/yolo/","link":"","permalink":"http://yoursite.com/2019/08/17/yolo/","excerpt":"YOLOv1缺点 对小目标检测效果不好 提取的region太少了，7*7*2 坐标定位不准确","text":"YOLOv1缺点 对小目标检测效果不好 提取的region太少了，7*7*2 坐标定位不准确 YOLOv2 - Better,Faster,StrongerBetter Batch Normalization 引入 Anchor Box 来预测Bouding box 维度聚类，使用K-means聚类bounding box，可以找到更好地box宽高 Faster 借鉴VGG,NIN思想，多次使用1*1和3*3等较小的卷积核以及使用全局平均池化，设计出darknet-19模型，大大节约计算量 Stronger COCO数据集少，ImageNet数据集多，使用wordtree结合了两个数据集的标签，使得能够检测9000多种目标 YOLOv3改进 特征提取器，设计Darknet-53，融合了darknet-19和残差网络等，更高效地提取特征 使用了多尺度预测，类似于 FPN(Feature Pyramid Network-特征金字塔网络)，三层不同scale的特征一起做bbox regression 分类预测使用二元交叉熵损失，边界框bbox regression 使用 平方和距离误差损失","categories":[],"tags":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://yoursite.com/tags/Deep-Learning/"}]},{"title":"Fine tuning Tutorial","slug":"Transfer-Learning","date":"2019-08-15T02:14:10.000Z","updated":"2019-08-15T02:47:58.000Z","comments":true,"path":"2019/08/15/Transfer-Learning/","link":"","permalink":"http://yoursite.com/2019/08/15/Transfer-Learning/","excerpt":"介绍 在深度学习领域，进行一个模型的训练往往需要大量的数据，否则会造成无法很好地拟合的问题。但是大多数情况下，现有数据量都是不够让模型很好地训练。","text":"介绍 在深度学习领域，进行一个模型的训练往往需要大量的数据，否则会造成无法很好地拟合的问题。但是大多数情况下，现有数据量都是不够让模型很好地训练。 举个栗子 直接 from scratch 训练容易过拟合，比如你有少量训练图像都是雪地里的阿拉斯加犬，然后直接from scratch去训练模型，经过很多epoch的迭代训练，很可能会造成模型学到的特征阿拉斯加犬都是在雪地里面，然后你给一张在草地里的阿拉斯加犬就无法识别，反而你给一个在雪地里面的藏獒被错误识别成阿拉斯加犬。这就是过拟合，学习到了图片中非常个性的特征，不具有很好的泛化能力。 方法Fine tuning就能较好地解决这个问题，现在常用的解决方案有两种: 使用pretrained model 做Feature extract，然后再去做分类等任务。(也就是固定预训练模型参数，把预训练模型当成一个完整的特征提取器，然后将给定image转化成一个feature vector) 使用pretrained model 做微调，增删模型后面若干层的网络结构，然后可以选择保留预训练模型的参数，这样可以保持模型的泛化能力，同时和后面调整的网络一起联合训练，使得模型更好地学习到新的数据特征。 优点 解决了我们小样本下使用复杂网络上容易过拟合的问题 节省了训练时间，因为网络前面几层提取的特征具备一定的泛化能力 技巧在数据量非常少的时候，建议使用预训练模型做特征抽取。在数据量较大的时候，建议使用fine tuning微调。 实战TODO","categories":[],"tags":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://yoursite.com/tags/Deep-Learning/"}]},{"title":"R-CNN系列目标检测网络解析","slug":"RCNN系列目标检测网络解析","date":"2019-08-13T12:44:43.000Z","updated":"2019-08-17T12:18:27.000Z","comments":true,"path":"2019/08/13/RCNN系列目标检测网络解析/","link":"","permalink":"http://yoursite.com/2019/08/13/RCNN%E7%B3%BB%E5%88%97%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%BD%91%E7%BB%9C%E8%A7%A3%E6%9E%90/","excerpt":"r-cnn:https://arxiv.org/pdf/1311.2524.pdffast r-cnn: https://arxiv.org/pdf/1504.08083.pdffaster r-cnn : https://arxiv.org/pdf/1506.01497.pdf 起源目标检测问题的起源:最初受到传统计算机视觉方法启发，使用滑动窗口检测器+SVM等分类器。但是有个问题:窗口的大小难以确定，因为物体是大小多样的。使用深度学习做目标检测的比较早期的方法就是R-CNN。","text":"r-cnn:https://arxiv.org/pdf/1311.2524.pdffast r-cnn: https://arxiv.org/pdf/1504.08083.pdffaster r-cnn : https://arxiv.org/pdf/1506.01497.pdf 起源目标检测问题的起源:最初受到传统计算机视觉方法启发，使用滑动窗口检测器+SVM等分类器。但是有个问题:窗口的大小难以确定，因为物体是大小多样的。使用深度学习做目标检测的比较早期的方法就是R-CNN。 R-CNN(Region convolutional neural network)流程输入一张图片，使用selective search（根据图像特征） 方法来提取region proposal （区域建议窗口），大约2000个左右，然后将 提取出来的2000个窗口 resize到统一尺寸，来符合CNN的输入，分别丢入CNN网络，然后用设计好的CNN的网络来提取特征，然后在最后加上SVM分类和BBox回归。 缺点需要对2000个proposal region逐个做CNN提取、分类、预测，很慢，而且有大量重复计算. 可以考虑的改进方案： 从窗口角度： 合理地选择窗口，减少运算量，提高运算效率 从网络结构的角度： 比如使用VGG16 ，resnet inception 等网络，来提高特征提取的精度和速度 Fast R-CNN流程先做SS，选出2000个窗口，但是不切出来，然后对原图整个做CNN提取特征，然后在CNN输出的特征图中按照2000个窗口的位置来切割，与之前先提取窗口，然后对每个窗口做CNN特征提取的效果是一样的。但是Fast-Rcnn只需要对大图做一次CNN，而RCNN需要对2000个小图分别做CNN，运算量比较大。另一个是用softmax来替换SVM，然后最后训练是使得multi-loss下降，multi-loss 包括bbox回归损失和分类损失。 改进(相对于R-CNN) 先使用卷积网络对图像进行特征提取，然后共享这个提取出来的feature map 因为使用SS提取的区域大小是不固定的，所以经过特征抽取网络后提取出来的feature map大小是不相同的，所以在特征抽取到分类回归层中间加上了ROI pooling网络结构，用于将不同大小的feature map分解成统一尺寸的特征(ROI pooling 的思想借鉴于 SPP-Net)。 使用softmax替换了SVM多分类器 缺点 使用SS的方法来提取2000个region开销太大，成为优化瓶颈，能否使用神经网络来寻找目标 Faster R-CNN 流程提出RPN网络（region proposal network）用于提取region，先在每个点找9个如图所示的anchor box 完整流程图 优点 使用RPN网络代替传统SS(Selective Search)提取region proposal的策略，大量缩短时间 Mask R-CNN改进 使用ROI Align 代替 ROI Pooling，使得检测更加精确 使用更强的特征提取网络ResNeXt替换VGG 在分类和回归分支加一个pixel级别的K(K是类别数)个feature map，用于预测原来图片每个pixel属于哪些类别","categories":[],"tags":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://yoursite.com/tags/Deep-Learning/"},{"name":"Object Detection","slug":"Object-Detection","permalink":"http://yoursite.com/tags/Object-Detection/"}]},{"title":"“好而不同”的集成学习","slug":"解析集成学习","date":"2019-08-11T05:58:31.000Z","updated":"2020-03-26T05:55:13.253Z","comments":true,"path":"2019/08/11/解析集成学习/","link":"","permalink":"http://yoursite.com/2019/08/11/%E8%A7%A3%E6%9E%90%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/","excerpt":"集成学习（Ensemble Learning）概述集成学习的思想就是组合多个弱学习器，得到一个强学习器。但注意，弱学习器不能太弱，比如在分类中，弱学习器的准确率最少要达到50%.","text":"集成学习（Ensemble Learning）概述集成学习的思想就是组合多个弱学习器，得到一个强学习器。但注意，弱学习器不能太弱，比如在分类中，弱学习器的准确率最少要达到50%. “好而不同”集成学习强调”好而不同”，这里的”好”是指学习器效果还不错，只要不太差就行；这里的”不同”指的是这些要集成的学习器各自在不同的方面还不错，集合在一起就能互相弥补，正所谓“三个臭皮匠赛过诸葛亮”. 针对每个学习器的个体，在选择弱学习器的时候，倾向于选择神经网络(Neural Network)，决策树(Decision Tree)这种类型(给定数据训练出来的学习器有一定随机性)，而不是选择SVM,朴素贝叶斯这种(对给定数据训练出来的学习器相差不大的学习器)。举个栗子，因为如果选择SVM可能学出的多个学习器是相似的，集成在一起就取不到更好的效果。但是如果选择决策树，训练出来的多个学习器很可能分支决策很不相同。所以多个”各有所长”的弱学习器就有机会集成为一个强学习器。另一方面，集成学习主要分为两种策略，Bagging和Boosting，在Bagging中首先是进行对给定数据进行N次Bootstrap抽样（又放回的抽样），然后训练N个弱学习器，这也体现了”不同”.在Boosting中，得到的多个学习器是在不同权重的数据样本下训练得到的，所以也是各有”不同”。","categories":[],"tags":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://yoursite.com/tags/Machine-Learning/"},{"name":"Ensemble Learning","slug":"Ensemble-Learning","permalink":"http://yoursite.com/tags/Ensemble-Learning/"}]},{"title":"深入理解ResNet","slug":"深入理解ResNet","date":"2019-08-09T10:55:56.000Z","updated":"2019-08-14T01:47:47.000Z","comments":true,"path":"2019/08/09/深入理解ResNet/","link":"","permalink":"http://yoursite.com/2019/08/09/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3ResNet/","excerpt":"ResNet能够work的主要原因: 作者说残差结构是为了解决网络退化的问题，作者猜测","text":"ResNet能够work的主要原因: 作者说残差结构是为了解决网络退化的问题，作者猜测 We conjecture that the deep plain nets may have exponentially low convergence rates, which impact the reducing of the training error. The reason for such optimization difficulties will be studied in the future. 认为 deep plain nets 可能有指数级低收敛率，限制了训练误差的进一步降低。他简单地比较了残差结构和常规结构在求解本征映射(identity map)时的优化难度，显然求解 F(x)=0 比求解 H(x) = x 容易得多也就是说能够更好地学习到差分特征，相当更容易学习到残差的那一部分。(这是ResNet有效地最主要原因) 残差网络对数据波动更敏感 我们回到设计 ResNet 的初衷： 为了解决深度网络的 退化 问题 。该问题的直接表现形式为： 深度网络在的训练误差比浅层网络高，无法做到使深层网络在训练数据集上“ 过拟合 ”。那么如何做到“过拟合”呢？ 答案就是我们需要使网络对数据波动更敏感，尽可能地去准确描述数据。而残差网络就是这样的一种网络结构。假设某几层 layer 要学习的函数 H(x) 如紫线所示，红色点表示采样点，对应一个数据样本。 在ResNet 中激活函数全部采用 ReLU， 我们知道 采用 ReLU 的网络是局部空间的线性网络的组合。对于数据点（5,5.1），即我们的 input 为5， 期望输出为5.1，假设为 plain network， 我们在 x =5 的附近，学习到的线性参数值为 w = 5.1/5 , 若数据点变成（5,5.2），我们仍可以用 w= 5.1/5 的线性网络近似，因为此时网络输出 5.1 与理想值 5.2 只相差 2% 而已. 所以在 plain net 中，网络对 数据不敏感。 数据的波动指的是相对对角线 y= x 的波动, 残差网络的思想是：我们用 y= x 先去粗略拟合数据， “波动”也即“拟合残差”就交给 weight layer 去拟合。数据点（5,5.1）对应的残差为（5,0.1），此时假设学习到的参数为 w=0.1/5 。同样地，若数据点变成（5,5.2），对应的残差为（5,0.2）。显然地，我们不可以用 0.1/5 近似了，因为若用0.1/5 近似，网络输出 0.1 和 0.2 相差了100%。网络需要调整 w 的值，以尽可能精确地描述残差。所以综上所述，残差网络对数据变得敏感，也即对“数据波动更敏感”，更容易做到“过拟合”。 集成学习思想，ResNet是由很多条路径集成学习得到的，对于每个block如果残差为0就退化为直连。如果所有resblock的残差都是0，那么就退化成VGG网络。 特征表示，跳层连接使得表达特征更加丰富，比如说前面网络层的浅层特征能够和深层的特征融合。2017年的DenseNet网络有类似的设计。 缓解梯度消失问题，梯度能够直接传到skip connection前面的网络层（不是主要原因，作者说这个梯度消失的问题使用Batch Normalization就能解决，但resNet确实有缓解梯度消失的效果） 参考https://zhuanlan.zhihu.com/p/54289848https://www.jianshu.com/p/ca6bee9eb888","categories":[],"tags":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://yoursite.com/tags/Deep-Learning/"},{"name":"ResNet","slug":"ResNet","permalink":"http://yoursite.com/tags/ResNet/"},{"name":"CNN","slug":"CNN","permalink":"http://yoursite.com/tags/CNN/"}]},{"title":"Batch Normalization解析","slug":"Batch-Normalization","date":"2019-08-08T08:47:43.000Z","updated":"2019-08-17T06:44:09.000Z","comments":true,"path":"2019/08/08/Batch-Normalization/","link":"","permalink":"http://yoursite.com/2019/08/08/Batch-Normalization/","excerpt":"论文链接 : https://arxiv.org/abs/1502.03167","text":"论文链接 : https://arxiv.org/abs/1502.03167 介绍Batch Normalization 是批归一化，用来解决神经网络中协方差偏移问题，就是每一层的分布很混乱，除非从第一层开始每一层的输入的分布都很有效，否则就得不到好的效果。如下图所示。 所以，为了解决这个问题，我们引入了Batch Normalization. 介绍一下在机器学习中，是如何做feature scaling，因为输入的不同变量分布不同，比如说x1可能是代表房子的房间数量，x2代表房子的大小多少平方，那么x2和x1很显然不属于统一量纲，所以要做归一化，如下图所示。 原理顾名思义，Batch Normalization是对一个batch的数据做处理， 求均值 除以标准差 仿射变换（可选）（有时候需要把均值和方差调整到某些范围时可以加上） 然后将Batch Normalization的结果送给激活函数层，才能比较好的发挥激活函数的作用。 举个栗子，比如像Sigmoid函数，如果不做Batch Normalization，可能会导致输入分布在两边（就是不集中在[-1，1] ），梯度就很小，链式相乘之后就会接近于0，做了Batch Normalization，把输入集中在0附近，使得激活函数更好地发挥作用。 pytorch实现pytorch api 1234567891011torch.nn.BatchNorm1d(num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)torch.nn.BatchNorm2d(num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) affine是仿射，track_running_stats是保留在训练时候的数据方差和均值，从而运用到测试中，因为在测试中是不方便计算方差和均值的，当batch_size很小的时候，应该设置为False。 训练模式下 track_running_stats=True, 这是常用的training时期待的行为，running_mean 和running_var会跟踪不同batch数据的mean和variance，但是仍然是用每个batch的mean和variance做normalization。 训练模式下, track_running_stats=False, 这时候running_mean 和running_var不跟踪跨batch数据的statistics了，但仍然用每个batch的mean和variance做normalization。 测试模式下, track_running_stats=True, 这是我们期待的test时候的行为，即使用training阶段估计的running_mean 和running_var。 测试模式下, track_running_stats=False，仍然用每个batch的mean和variance做normalization。 要注意在训练的时候选择model.train()模式在测试的时候选择model.eval()模式，这样Batch Normalization中的参数才会固定。 知乎上有个BN为什么能够解决梯度消失和爆炸问题的回答写的很好:https://www.zhihu.com/question/38102762/answer/391649040 参考:https://www.zhihu.com/question/282672547","categories":[],"tags":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://yoursite.com/tags/Deep-Learning/"}]},{"title":"经典CNN结构解析与实现","slug":"CNN-Network","date":"2019-08-02T01:36:03.000Z","updated":"2020-03-26T05:55:04.467Z","comments":true,"path":"2019/08/02/CNN-Network/","link":"","permalink":"http://yoursite.com/2019/08/02/CNN-Network/","excerpt":"实现代码地址：Github","text":"实现代码地址：Github 目录 AlexNet VGG Google Inception Net ResNet DenseNet MobileNet Shuffle Net AlexNet 首次使用CNN组建的深度网络在ImageNet上达到最好效果 它使用Relu 激活函数代替了传统的激活函数(Sigmoid/Tanh) 使用Dropout 解决过拟合问题 计算量较大 VGG VGG使用连续的几个3*3卷积核代替AlexNet中较大的卷积核，减少计算量。 VGG Net中采用的卷积核是非常一致的，全都是3*3的filter VGG 分为4-5个block，每个block包含若干个3*3的卷积层和一个2*2的MaxPooling层所以得到的conv4_3是16倍的下采样的feature map Inception Net 设计了Inception Block，采用了不同尺度的filter，size为1*1,3*3,5*5，获得了不同scale的特征，具有对不同尺度特征的提取能力，而且还通过1*1的卷积层来大大降低运算。 在卷积层结束后，使用全局AveragePooling，避免使用全连接层 ResNet 在VGG网络后，研究人员发现仅仅堆叠越来越多层的CNN 或 全连接层等是无法再提高准确率，主要原因就是梯度消失的问题，因为在多层神经网络中，梯度传到最前面的网络层就非常接近0了，导致前面网络层的参数更新很慢。于是提出ResNet去解决这个梯度消失的问题。 ResNet主要是设计了一个ResBlock。ResBlock使用skip connect 跳层连接，使得梯度能够有效地回传，从而参数得以更新，才敢设计比VGG深很多的网络。 DenseNet 设计思路与ResNet非常相似，但实际上一个很大的区别是，它是做多channel的特征的拼接，而ResNet是做求和计算 DenseNet主要包含两个模块，DenseBlock和Transition层，每个DenseBlock的内部是将第N层之前的feature map都经过卷积处理到固定shape拼接到第N层，Transition作为缓冲层是将维度进行降低，减少计算量 优点：梯度消失问题得到改善，特征复用，使用了multi-scale的特征,参数少，因为特征图的channel不像之前的那么多 缺点: 耗费显存(concat拼接操作) MobileNet 解决深度学习网络移动设备上的运行速度问题，提出的高效的网络，在模型大小显著减少的情况下，对准确率不造成太大影响 使用 depthwise separable convolution 代替传统卷积网络。 depthwise separable convolution depthwise卷积 对输入的D*D*M的M个通道，每个通道使用一个filter进行卷积，即使用M个卷积核分别对M个通道进行卷积，得到feature mapD*D*M pointwise卷积 对经过上面步骤得到的feature mapD*D*M的每个cell(shape为 1*1*M) 使用1*1*M*N卷积核进行卷积 SqueezeNetShuffle NetNIN(Network In Network) 提出1*1的卷积filter来构建新的卷积单元 1*1的卷积核的优势: 减少运算，加强多通道的特征融合，提高模型非线性变换能力 使用average pooling 来代替最后面的全连接层，大大减少计算量","categories":[],"tags":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://yoursite.com/tags/Deep-Learning/"},{"name":"Image Classification","slug":"Image-Classification","permalink":"http://yoursite.com/tags/Image-Classification/"},{"name":"Feature Extract","slug":"Feature-Extract","permalink":"http://yoursite.com/tags/Feature-Extract/"}]},{"title":"《You Only Look Once》YOLOv1论文笔记","slug":"YOLOv1","date":"2019-08-01T08:25:01.000Z","updated":"2019-08-02T01:18:14.000Z","comments":true,"path":"2019/08/01/YOLOv1/","link":"","permalink":"http://yoursite.com/2019/08/01/YOLOv1/","excerpt":"YOLO v1论文:《You Only Look Once: Uniﬁed, Real-Time Object Detection》论文地址：http://www.arxiv.org/pdf/1506.02640.pdf","text":"YOLO v1论文:《You Only Look Once: Uniﬁed, Real-Time Object Detection》论文地址：http://www.arxiv.org/pdf/1506.02640.pdf 简介作者提出把目标检测任务当做回归任务来做，用一个神经网络来完成bbox(bounding box)以及class probabilities(类别概率)的回归，因为网络是单个完整的，不同于Faster R-CNN是分为RPN(Region Proposal Network,区域建议网络，用来生成一些proposal，输给后续的回归网络)和回归网络。所以YOLO网络是可以端到端的训练。 网络结构 YOLO系统流程 输入图片img resize到指定尺寸 通过预先设计好的多层CNN(一般包括特征抽取的VGG，以及回归层等) 根据回归层输出的坐标和置信度confidence来对proposal进行筛选 主要的网络结构如图如上图所示，输入一个图片，resize到448*448的，经过N多卷积网络层得到7*7*30的feature map 图片源于知乎用户这个维度30的意义如下图所示，包括confidence*2,(x1,y1)(x2,y2)四个坐标*2,20个类别概率(哪个概率大就是哪一类，用softmax实现)，每一个30维的vector代表一个7*7的feature map 的每一个cell里面的信息。 置信度在训练时计算如上图所示，Pr(object)就是选择一个cell中与训练样本ground truth的IOU大的那个proposal为1，另一个为0，所以这个置信度即为IOU或0。 Loss Function 如图所示，损失函数包括三部分：坐标回归损失、分类损失和置信度损失。坐标回归损失只是针对那些被认定为包含object的proposal才进行计算，对于没有检测到object的proposal不需要坐标回归的loss，分类损失也是检测到object的proposal要计算。还有一个置信度误差，不管有没有检测到object都要去计算。 Problem 每个vector的30维中只有一个20维的class probability ，但是有两个5维(4个坐标+1个置信度)向量，这代表了实际上7*7的feature map中的每一个单元都只能预测一个object，那么对于每个object为什么要使用两个回归向量呢？是为了精确地解决回归问题，最后这两个回归出来的proposal最多保留IOU大的那一个。","categories":[],"tags":[{"name":"Computer Vision","slug":"Computer-Vision","permalink":"http://yoursite.com/tags/Computer-Vision/"},{"name":"Object Detection","slug":"Object-Detection","permalink":"http://yoursite.com/tags/Object-Detection/"},{"name":"Notes","slug":"Notes","permalink":"http://yoursite.com/tags/Notes/"}]},{"title":"Hello World","slug":"hello-world","date":"2017-05-26T03:21:36.000Z","updated":"2019-08-15T02:50:57.000Z","comments":true,"path":"2017/05/26/hello-world/","link":"","permalink":"http://yoursite.com/2017/05/26/hello-world/","excerpt":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}